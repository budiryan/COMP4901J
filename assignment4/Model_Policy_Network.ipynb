{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model-Based RL\n",
    "In this exercise you will implement a policy and model network which work in tandem to solve the CartPole reinforcement learning problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is a model and why would we want to use one? In this case, a model is going to be a neural network that attempts to learn the dynamics of the real environment. For example, in the CartPole we would like a model to be able to predict the next position of the Cart given the previous position and an action. By learning an accurate model, we can train our agent using the model rather than requiring to use the real environment every time. While this may seem less useful when the real environment is itself a simulation, like in our CartPole task, it can have huge advantages when attempting to learn policies for acting in the physical world."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How are we going to accomplish this in Tensorflow? We are going to be using a neural network that will learn the transition dynamics between a previous observation and action, and the expected new observation, reward, and done state. Our training procedure will involve switching between training our model using the real environment, and training our agentâ€™s policy using the model environment. By using this approach we will be able to learn a policy that allows our agent to solve the CartPole task without actually ever training the policy on the real environment! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading libraries and starting CartPole environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "try:\n",
    "    import cPickle as pickle\n",
    "except:\n",
    "    import pickle\n",
    "import tensorflow as tf\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "if sys.version_info.major > 2:\n",
    "    xrange = range\n",
    "del sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "env = gym.make('CartPole-v0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "H = 8 # number of hidden layer neurons\n",
    "learning_rate = 1e-2\n",
    "gamma = 0.99 # discount factor for reward\n",
    "decay_rate = 0.99 # decay factor for RMSProp leaky sum of grad^2\n",
    "resume = False # resume from previous checkpoint?\n",
    "\n",
    "model_bs = 3 # Batch size when learning from model\n",
    "real_bs = 3 # Batch size when learning from real environment\n",
    "\n",
    "# model initialization\n",
    "D = 4 # input dimensionality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Policy Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "observations = tf.placeholder(tf.float32, [None,4] , name=\"input_x\")\n",
    "W1 = tf.get_variable(\"W1\", shape=[4, H],\n",
    "           initializer=tf.contrib.layers.xavier_initializer())\n",
    "layer1 = tf.nn.relu(tf.matmul(observations,W1))\n",
    "W2 = tf.get_variable(\"W2\", shape=[H, 1],\n",
    "           initializer=tf.contrib.layers.xavier_initializer())\n",
    "score = tf.matmul(layer1,W2)\n",
    "probability = tf.nn.sigmoid(score)\n",
    "\n",
    "tvars = tf.trainable_variables()\n",
    "input_y = tf.placeholder(tf.float32,[None,1], name=\"input_y\")\n",
    "advantages = tf.placeholder(tf.float32,name=\"reward_signal\")\n",
    "adam = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "W1Grad = tf.placeholder(tf.float32,name=\"batch_grad1\")\n",
    "W2Grad = tf.placeholder(tf.float32,name=\"batch_grad2\")\n",
    "batchGrad = [W1Grad,W2Grad]\n",
    "\n",
    "################################################################################\n",
    "# TODO: Implement the loss function.                                           #\n",
    "# This sends the weights in the direction of making actions that gave good     #\n",
    "# advantage (reward overtime) more likely, and actions that didn't less likely.#\n",
    "################################################################################\n",
    "loglik = tf.log(input_y*(input_y - probability) + (1 - input_y)*(input_y + probability))\n",
    "loss = -tf.reduce_mean(loglik * advantages) \n",
    "newGrads = tf.gradients(loss,tvars)\n",
    "adam = tf.train.AdamOptimizer(learning_rate=learning_rate) # Our optimizer\n",
    "################################################################################\n",
    "#                                 END OF YOUR CODE                             #\n",
    "################################################################################\n",
    "\n",
    "newGrads = tf.gradients(loss,tvars)\n",
    "updateGrads = adam.apply_gradients(zip(batchGrad,tvars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Network\n",
    "Here we implement a multi-layer neural network that predicts the next observation, reward, and done state from a current state and action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "mH = 256 # model layer size\n",
    "\n",
    "input_data = tf.placeholder(tf.float32, [None, 5])\n",
    "with tf.variable_scope('rnnlm'):\n",
    "    softmax_w = tf.get_variable(\"softmax_w\", [mH, 50])\n",
    "    softmax_b = tf.get_variable(\"softmax_b\", [50])\n",
    "\n",
    "previous_state = tf.placeholder(tf.float32, [None,5] , name=\"previous_state\")\n",
    "W1M = tf.get_variable(\"W1M\", shape=[5, mH],\n",
    "           initializer=tf.contrib.layers.xavier_initializer())\n",
    "B1M = tf.Variable(tf.zeros([mH]),name=\"B1M\")\n",
    "layer1M = tf.nn.relu(tf.matmul(previous_state,W1M) + B1M)\n",
    "W2M = tf.get_variable(\"W2M\", shape=[mH, mH],\n",
    "           initializer=tf.contrib.layers.xavier_initializer())\n",
    "B2M = tf.Variable(tf.zeros([mH]),name=\"B2M\")\n",
    "layer2M = tf.nn.relu(tf.matmul(layer1M,W2M) + B2M)\n",
    "wO = tf.get_variable(\"wO\", shape=[mH, 4],\n",
    "           initializer=tf.contrib.layers.xavier_initializer())\n",
    "wR = tf.get_variable(\"wR\", shape=[mH, 1],\n",
    "           initializer=tf.contrib.layers.xavier_initializer())\n",
    "wD = tf.get_variable(\"wD\", shape=[mH, 1],\n",
    "           initializer=tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "bO = tf.Variable(tf.zeros([4]),name=\"bO\")\n",
    "bR = tf.Variable(tf.zeros([1]),name=\"bR\")\n",
    "bD = tf.Variable(tf.ones([1]),name=\"bD\")\n",
    "\n",
    "\n",
    "predicted_observation = tf.matmul(layer2M,wO,name=\"predicted_observation\") + bO\n",
    "predicted_reward = tf.matmul(layer2M,wR,name=\"predicted_reward\") + bR\n",
    "predicted_done = tf.sigmoid(tf.matmul(layer2M,wD,name=\"predicted_done\") + bD)\n",
    "\n",
    "true_observation = tf.placeholder(tf.float32,[None,4],name=\"true_observation\")\n",
    "true_reward = tf.placeholder(tf.float32,[None,1],name=\"true_reward\")\n",
    "true_done = tf.placeholder(tf.float32,[None,1],name=\"true_done\")\n",
    "\n",
    "\n",
    "predicted_state = tf.concat([predicted_observation,predicted_reward,predicted_done],1)\n",
    "\n",
    "observation_loss = tf.square(true_observation - predicted_observation)\n",
    "\n",
    "reward_loss = tf.square(true_reward - predicted_reward)\n",
    "\n",
    "done_loss = tf.multiply(predicted_done, true_done) + tf.multiply(1-predicted_done, 1-true_done)\n",
    "done_loss = -tf.log(done_loss)\n",
    "\n",
    "model_loss = tf.reduce_mean(observation_loss + done_loss + reward_loss)\n",
    "\n",
    "modelAdam = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "updateModel = modelAdam.minimize(model_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper-functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resetGradBuffer(gradBuffer):\n",
    "    for ix,grad in enumerate(gradBuffer):\n",
    "        gradBuffer[ix] = grad * 0\n",
    "    return gradBuffer\n",
    "\n",
    "def discount_rewards(r):\n",
    "    ################################################################################\n",
    "    # TODO: Implement the discounted rewards function                              #\n",
    "    # Return discounted rewards weighed by gamma. Each reward will be replaced     #\n",
    "    # with a weight reward that involves itself and all the other rewards occuring #\n",
    "    # after it. The later the reward after it happens, the less effect it has on   #\n",
    "    # the current rewards's discounted reward                                      #\n",
    "    # Hint: [r0, r1, r2, ..., r_N] will look someting like:                        #\n",
    "    #       [(r0 + r1*gamma^1 + ... r_N*gamma^N), (r1 + r2*gamma^1 + ...), ...]    #\n",
    "    ################################################################################\n",
    "    discounted_rewards = np.zeros(r.shape)\n",
    "    running_discount = 0\n",
    "    for i in reversed(range(len(r))):\n",
    "        running_discount = running_discount * gamma + r[i]\n",
    "        discounted_rewards[i] = running_discount\n",
    "    return discounted_rewards\n",
    "    ################################################################################\n",
    "    #                                 END OF YOUR CODE                             #\n",
    "    ################################################################################\n",
    "\n",
    "# This function uses our model to produce a new state when given a previous state and action\n",
    "def stepModel(sess, xs, action):\n",
    "    toFeed = np.reshape(np.hstack([xs[-1][0],np.array(action)]),[1,5])\n",
    "    myPredict = sess.run([predicted_state],feed_dict={previous_state: toFeed})\n",
    "    reward = myPredict[0][:,4]\n",
    "    observation = myPredict[0][:,0:4]\n",
    "    observation[:,0] = np.clip(observation[:,0],-2.4,2.4)\n",
    "    observation[:,2] = np.clip(observation[:,2],-0.4,0.4)\n",
    "    doneP = np.clip(myPredict[0][:,5],0,1)\n",
    "    if doneP > 0.1 or len(xs)>= 300:\n",
    "        done = True\n",
    "    else:\n",
    "        done = False\n",
    "    return observation, reward, done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Policy and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "World Perf: Episode 4.000000. Reward 18.000000. action: 0.000000. mean reward 18.000000.\n",
      "World Perf: Episode 7.000000. Reward 16.000000. action: 1.000000. mean reward 17.980000.\n",
      "World Perf: Episode 10.000000. Reward 17.000000. action: 0.000000. mean reward 17.970200.\n",
      "World Perf: Episode 13.000000. Reward 17.666667. action: 1.000000. mean reward 17.967165.\n",
      "World Perf: Episode 16.000000. Reward 32.666667. action: 1.000000. mean reward 18.114160.\n",
      "World Perf: Episode 19.000000. Reward 22.333333. action: 0.000000. mean reward 18.156351.\n",
      "World Perf: Episode 22.000000. Reward 20.000000. action: 1.000000. mean reward 18.174788.\n",
      "World Perf: Episode 25.000000. Reward 28.333333. action: 0.000000. mean reward 18.276373.\n",
      "World Perf: Episode 28.000000. Reward 28.333333. action: 0.000000. mean reward 18.376943.\n",
      "World Perf: Episode 31.000000. Reward 16.000000. action: 1.000000. mean reward 18.353174.\n",
      "World Perf: Episode 34.000000. Reward 18.000000. action: 1.000000. mean reward 18.349642.\n",
      "World Perf: Episode 37.000000. Reward 15.666667. action: 1.000000. mean reward 18.322812.\n",
      "World Perf: Episode 40.000000. Reward 16.333333. action: 0.000000. mean reward 18.302917.\n",
      "World Perf: Episode 43.000000. Reward 31.000000. action: 1.000000. mean reward 18.429888.\n",
      "World Perf: Episode 46.000000. Reward 21.000000. action: 0.000000. mean reward 18.455589.\n",
      "World Perf: Episode 49.000000. Reward 33.333333. action: 1.000000. mean reward 18.604367.\n",
      "World Perf: Episode 52.000000. Reward 16.333333. action: 1.000000. mean reward 18.581656.\n",
      "World Perf: Episode 55.000000. Reward 16.666667. action: 0.000000. mean reward 18.562506.\n",
      "World Perf: Episode 58.000000. Reward 28.333333. action: 0.000000. mean reward 18.660215.\n",
      "World Perf: Episode 61.000000. Reward 17.000000. action: 1.000000. mean reward 18.643613.\n",
      "World Perf: Episode 64.000000. Reward 16.666667. action: 0.000000. mean reward 18.623843.\n",
      "World Perf: Episode 67.000000. Reward 21.333333. action: 0.000000. mean reward 18.650938.\n",
      "World Perf: Episode 70.000000. Reward 38.333333. action: 0.000000. mean reward 18.847762.\n",
      "World Perf: Episode 73.000000. Reward 35.666667. action: 0.000000. mean reward 19.015951.\n",
      "World Perf: Episode 76.000000. Reward 28.000000. action: 1.000000. mean reward 19.105791.\n",
      "World Perf: Episode 79.000000. Reward 19.000000. action: 0.000000. mean reward 19.104734.\n",
      "World Perf: Episode 82.000000. Reward 29.000000. action: 0.000000. mean reward 19.203686.\n",
      "World Perf: Episode 85.000000. Reward 20.666667. action: 0.000000. mean reward 19.218316.\n",
      "World Perf: Episode 88.000000. Reward 18.666667. action: 1.000000. mean reward 19.212800.\n",
      "World Perf: Episode 91.000000. Reward 25.333333. action: 0.000000. mean reward 19.274005.\n",
      "World Perf: Episode 94.000000. Reward 16.666667. action: 1.000000. mean reward 19.247931.\n",
      "World Perf: Episode 97.000000. Reward 23.333333. action: 1.000000. mean reward 19.288786.\n",
      "World Perf: Episode 100.000000. Reward 22.333333. action: 1.000000. mean reward 19.319231.\n",
      "World Perf: Episode 103.000000. Reward 23.000000. action: 1.000000. mean reward 19.356039.\n",
      "World Perf: Episode 106.000000. Reward 24.666667. action: 1.000000. mean reward 19.408382.\n",
      "World Perf: Episode 109.000000. Reward 18.333333. action: 0.000000. mean reward 19.544058.\n",
      "World Perf: Episode 112.000000. Reward 24.666667. action: 1.000000. mean reward 19.667685.\n",
      "World Perf: Episode 115.000000. Reward 21.000000. action: 0.000000. mean reward 20.746378.\n",
      "World Perf: Episode 118.000000. Reward 36.333333. action: 1.000000. mean reward 20.780479.\n",
      "World Perf: Episode 121.000000. Reward 36.000000. action: 0.000000. mean reward 20.810799.\n",
      "World Perf: Episode 124.000000. Reward 17.000000. action: 1.000000. mean reward 20.626385.\n",
      "World Perf: Episode 127.000000. Reward 22.000000. action: 0.000000. mean reward 20.496286.\n",
      "World Perf: Episode 130.000000. Reward 12.666667. action: 0.000000. mean reward 20.354670.\n",
      "World Perf: Episode 133.000000. Reward 15.000000. action: 1.000000. mean reward 20.370066.\n",
      "World Perf: Episode 136.000000. Reward 22.666667. action: 0.000000. mean reward 20.399239.\n",
      "World Perf: Episode 139.000000. Reward 21.333333. action: 1.000000. mean reward 20.257967.\n",
      "World Perf: Episode 142.000000. Reward 31.000000. action: 1.000000. mean reward 20.301817.\n",
      "World Perf: Episode 145.000000. Reward 45.333333. action: 1.000000. mean reward 20.915995.\n",
      "World Perf: Episode 148.000000. Reward 19.333333. action: 0.000000. mean reward 21.842802.\n",
      "World Perf: Episode 151.000000. Reward 33.000000. action: 0.000000. mean reward 21.799517.\n",
      "World Perf: Episode 154.000000. Reward 32.333333. action: 1.000000. mean reward 22.672892.\n",
      "World Perf: Episode 157.000000. Reward 28.333333. action: 0.000000. mean reward 22.812965.\n",
      "World Perf: Episode 160.000000. Reward 23.666667. action: 0.000000. mean reward 22.631613.\n",
      "World Perf: Episode 163.000000. Reward 29.000000. action: 0.000000. mean reward 22.520584.\n",
      "World Perf: Episode 166.000000. Reward 29.000000. action: 1.000000. mean reward 22.606287.\n",
      "World Perf: Episode 169.000000. Reward 26.333333. action: 1.000000. mean reward 24.573761.\n",
      "World Perf: Episode 172.000000. Reward 41.000000. action: 0.000000. mean reward 24.719114.\n",
      "World Perf: Episode 175.000000. Reward 14.000000. action: 0.000000. mean reward 26.609426.\n",
      "World Perf: Episode 178.000000. Reward 27.000000. action: 1.000000. mean reward 28.247637.\n",
      "World Perf: Episode 181.000000. Reward 17.333333. action: 1.000000. mean reward 27.929873.\n",
      "World Perf: Episode 184.000000. Reward 28.000000. action: 1.000000. mean reward 27.817360.\n",
      "World Perf: Episode 187.000000. Reward 17.000000. action: 0.000000. mean reward 27.612091.\n",
      "World Perf: Episode 190.000000. Reward 49.666667. action: 1.000000. mean reward 28.145493.\n",
      "World Perf: Episode 193.000000. Reward 39.000000. action: 0.000000. mean reward 28.167673.\n",
      "World Perf: Episode 196.000000. Reward 20.333333. action: 0.000000. mean reward 27.991203.\n",
      "World Perf: Episode 199.000000. Reward 49.666667. action: 0.000000. mean reward 28.236998.\n",
      "World Perf: Episode 202.000000. Reward 34.333333. action: 1.000000. mean reward 28.077360.\n",
      "World Perf: Episode 205.000000. Reward 29.333333. action: 1.000000. mean reward 27.888575.\n",
      "World Perf: Episode 208.000000. Reward 66.000000. action: 1.000000. mean reward 28.112509.\n",
      "World Perf: Episode 211.000000. Reward 29.666667. action: 1.000000. mean reward 27.979425.\n",
      "World Perf: Episode 214.000000. Reward 23.000000. action: 0.000000. mean reward 27.730034.\n",
      "World Perf: Episode 217.000000. Reward 65.000000. action: 1.000000. mean reward 27.951525.\n",
      "World Perf: Episode 220.000000. Reward 50.666667. action: 0.000000. mean reward 29.590021.\n",
      "World Perf: Episode 223.000000. Reward 27.333333. action: 1.000000. mean reward 29.351511.\n",
      "World Perf: Episode 226.000000. Reward 68.333333. action: 1.000000. mean reward 29.520369.\n",
      "World Perf: Episode 229.000000. Reward 104.000000. action: 1.000000. mean reward 30.038828.\n",
      "World Perf: Episode 232.000000. Reward 30.000000. action: 1.000000. mean reward 29.795904.\n",
      "World Perf: Episode 235.000000. Reward 46.000000. action: 1.000000. mean reward 29.750031.\n",
      "World Perf: Episode 238.000000. Reward 42.333333. action: 0.000000. mean reward 29.728989.\n",
      "World Perf: Episode 241.000000. Reward 51.666667. action: 1.000000. mean reward 29.709505.\n",
      "World Perf: Episode 244.000000. Reward 29.333333. action: 1.000000. mean reward 30.036453.\n",
      "World Perf: Episode 247.000000. Reward 34.666667. action: 1.000000. mean reward 31.598310.\n",
      "World Perf: Episode 250.000000. Reward 33.000000. action: 1.000000. mean reward 31.604067.\n",
      "World Perf: Episode 253.000000. Reward 42.333333. action: 1.000000. mean reward 33.705059.\n",
      "World Perf: Episode 256.000000. Reward 32.000000. action: 1.000000. mean reward 33.585106.\n",
      "World Perf: Episode 259.000000. Reward 52.000000. action: 0.000000. mean reward 33.617588.\n",
      "World Perf: Episode 262.000000. Reward 35.666667. action: 1.000000. mean reward 36.317898.\n",
      "World Perf: Episode 265.000000. Reward 48.000000. action: 0.000000. mean reward 36.565731.\n",
      "World Perf: Episode 268.000000. Reward 21.666667. action: 1.000000. mean reward 36.247585.\n",
      "World Perf: Episode 271.000000. Reward 43.000000. action: 0.000000. mean reward 37.300812.\n",
      "World Perf: Episode 274.000000. Reward 61.333333. action: 1.000000. mean reward 37.583279.\n",
      "World Perf: Episode 277.000000. Reward 34.666667. action: 0.000000. mean reward 37.238285.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "World Perf: Episode 280.000000. Reward 32.333333. action: 1.000000. mean reward 36.990456.\n",
      "World Perf: Episode 283.000000. Reward 40.666667. action: 0.000000. mean reward 36.752354.\n",
      "World Perf: Episode 286.000000. Reward 56.666667. action: 1.000000. mean reward 36.649494.\n",
      "World Perf: Episode 289.000000. Reward 54.000000. action: 1.000000. mean reward 39.445518.\n",
      "World Perf: Episode 292.000000. Reward 44.666667. action: 0.000000. mean reward 39.177181.\n",
      "World Perf: Episode 295.000000. Reward 50.333333. action: 0.000000. mean reward 39.042606.\n",
      "World Perf: Episode 298.000000. Reward 58.000000. action: 0.000000. mean reward 41.541775.\n",
      "World Perf: Episode 301.000000. Reward 21.000000. action: 0.000000. mean reward 41.030075.\n",
      "World Perf: Episode 304.000000. Reward 29.666667. action: 1.000000. mean reward 40.562202.\n",
      "World Perf: Episode 307.000000. Reward 34.000000. action: 1.000000. mean reward 40.206768.\n",
      "World Perf: Episode 310.000000. Reward 66.333333. action: 1.000000. mean reward 40.105869.\n",
      "World Perf: Episode 313.000000. Reward 59.333333. action: 1.000000. mean reward 39.949078.\n",
      "World Perf: Episode 316.000000. Reward 38.333333. action: 1.000000. mean reward 39.591496.\n",
      "World Perf: Episode 319.000000. Reward 53.333333. action: 0.000000. mean reward 39.389233.\n",
      "World Perf: Episode 322.000000. Reward 20.333333. action: 1.000000. mean reward 38.937550.\n",
      "World Perf: Episode 325.000000. Reward 23.333333. action: 1.000000. mean reward 41.156979.\n",
      "World Perf: Episode 328.000000. Reward 41.333333. action: 1.000000. mean reward 44.111725.\n",
      "World Perf: Episode 331.000000. Reward 93.333333. action: 1.000000. mean reward 44.242386.\n",
      "World Perf: Episode 334.000000. Reward 76.000000. action: 1.000000. mean reward 44.186066.\n",
      "World Perf: Episode 337.000000. Reward 57.333333. action: 1.000000. mean reward 43.992855.\n",
      "World Perf: Episode 340.000000. Reward 77.000000. action: 0.000000. mean reward 47.268101.\n",
      "World Perf: Episode 343.000000. Reward 35.000000. action: 1.000000. mean reward 48.930466.\n",
      "World Perf: Episode 346.000000. Reward 53.333333. action: 0.000000. mean reward 51.493099.\n",
      "World Perf: Episode 349.000000. Reward 62.000000. action: 1.000000. mean reward 52.353043.\n",
      "World Perf: Episode 352.000000. Reward 56.000000. action: 1.000000. mean reward 54.842361.\n",
      "World Perf: Episode 355.000000. Reward 35.000000. action: 0.000000. mean reward 54.190796.\n",
      "World Perf: Episode 358.000000. Reward 56.000000. action: 1.000000. mean reward 65.276154.\n",
      "World Perf: Episode 361.000000. Reward 29.666667. action: 1.000000. mean reward 82.526970.\n",
      "World Perf: Episode 364.000000. Reward 52.000000. action: 0.000000. mean reward 84.225517.\n",
      "World Perf: Episode 367.000000. Reward 64.333333. action: 0.000000. mean reward 86.023399.\n",
      "World Perf: Episode 370.000000. Reward 40.333333. action: 0.000000. mean reward 95.277916.\n",
      "World Perf: Episode 373.000000. Reward 24.000000. action: 1.000000. mean reward 97.937843.\n",
      "World Perf: Episode 376.000000. Reward 36.333333. action: 0.000000. mean reward 97.863533.\n",
      "World Perf: Episode 379.000000. Reward 54.000000. action: 1.000000. mean reward 101.186577.\n",
      "World Perf: Episode 382.000000. Reward 46.333333. action: 0.000000. mean reward 103.803123.\n",
      "World Perf: Episode 385.000000. Reward 37.666667. action: 1.000000. mean reward 106.265007.\n",
      "World Perf: Episode 388.000000. Reward 81.000000. action: 1.000000. mean reward 106.618134.\n",
      "World Perf: Episode 391.000000. Reward 109.000000. action: 0.000000. mean reward 106.590385.\n",
      "World Perf: Episode 394.000000. Reward 39.333333. action: 0.000000. mean reward 106.514229.\n",
      "World Perf: Episode 397.000000. Reward 46.666667. action: 1.000000. mean reward 106.514885.\n",
      "World Perf: Episode 400.000000. Reward 44.000000. action: 0.000000. mean reward 107.781456.\n",
      "World Perf: Episode 403.000000. Reward 39.333333. action: 0.000000. mean reward 108.967438.\n",
      "World Perf: Episode 406.000000. Reward 53.666667. action: 1.000000. mean reward 107.600731.\n",
      "World Perf: Episode 409.000000. Reward 51.666667. action: 0.000000. mean reward 108.143806.\n",
      "World Perf: Episode 412.000000. Reward 80.666667. action: 0.000000. mean reward 107.455986.\n",
      "World Perf: Episode 415.000000. Reward 39.666667. action: 1.000000. mean reward 106.151604.\n",
      "World Perf: Episode 418.000000. Reward 71.000000. action: 1.000000. mean reward 105.105461.\n",
      "World Perf: Episode 421.000000. Reward 58.000000. action: 0.000000. mean reward 103.654755.\n",
      "World Perf: Episode 424.000000. Reward 46.666667. action: 1.000000. mean reward 103.228996.\n",
      "World Perf: Episode 427.000000. Reward 56.666667. action: 1.000000. mean reward 109.141838.\n",
      "World Perf: Episode 430.000000. Reward 53.333333. action: 1.000000. mean reward 108.688293.\n",
      "World Perf: Episode 433.000000. Reward 41.000000. action: 0.000000. mean reward 113.657082.\n",
      "World Perf: Episode 436.000000. Reward 33.000000. action: 1.000000. mean reward 111.874138.\n",
      "World Perf: Episode 439.000000. Reward 73.333333. action: 0.000000. mean reward 110.686310.\n",
      "World Perf: Episode 442.000000. Reward 46.333333. action: 0.000000. mean reward 112.222168.\n",
      "World Perf: Episode 445.000000. Reward 37.333333. action: 0.000000. mean reward 110.496674.\n",
      "World Perf: Episode 448.000000. Reward 32.666667. action: 0.000000. mean reward 111.842995.\n",
      "World Perf: Episode 451.000000. Reward 42.666667. action: 1.000000. mean reward 110.687431.\n",
      "World Perf: Episode 454.000000. Reward 77.666667. action: 0.000000. mean reward 112.790619.\n",
      "World Perf: Episode 457.000000. Reward 53.333333. action: 0.000000. mean reward 111.213158.\n",
      "World Perf: Episode 460.000000. Reward 26.333333. action: 1.000000. mean reward 109.407372.\n",
      "World Perf: Episode 463.000000. Reward 51.666667. action: 0.000000. mean reward 107.834351.\n",
      "World Perf: Episode 466.000000. Reward 30.666667. action: 0.000000. mean reward 106.140984.\n",
      "World Perf: Episode 469.000000. Reward 41.666667. action: 0.000000. mean reward 106.337608.\n",
      "World Perf: Episode 472.000000. Reward 71.666667. action: 0.000000. mean reward 105.574577.\n",
      "World Perf: Episode 475.000000. Reward 30.000000. action: 0.000000. mean reward 103.884727.\n",
      "World Perf: Episode 478.000000. Reward 72.000000. action: 0.000000. mean reward 105.301605.\n",
      "World Perf: Episode 481.000000. Reward 43.000000. action: 0.000000. mean reward 103.704338.\n",
      "World Perf: Episode 484.000000. Reward 79.000000. action: 1.000000. mean reward 102.900917.\n",
      "World Perf: Episode 487.000000. Reward 98.333333. action: 0.000000. mean reward 102.580879.\n",
      "World Perf: Episode 490.000000. Reward 75.666667. action: 0.000000. mean reward 101.409019.\n",
      "World Perf: Episode 493.000000. Reward 63.000000. action: 0.000000. mean reward 100.400993.\n",
      "World Perf: Episode 496.000000. Reward 71.333333. action: 1.000000. mean reward 99.421715.\n",
      "World Perf: Episode 499.000000. Reward 39.333333. action: 0.000000. mean reward 98.007996.\n",
      "World Perf: Episode 502.000000. Reward 108.666667. action: 1.000000. mean reward 97.435112.\n",
      "World Perf: Episode 505.000000. Reward 57.666667. action: 1.000000. mean reward 96.401726.\n",
      "World Perf: Episode 508.000000. Reward 119.000000. action: 0.000000. mean reward 95.916542.\n",
      "World Perf: Episode 511.000000. Reward 83.666667. action: 1.000000. mean reward 94.976349.\n",
      "World Perf: Episode 514.000000. Reward 61.000000. action: 0.000000. mean reward 93.832649.\n",
      "World Perf: Episode 517.000000. Reward 37.000000. action: 0.000000. mean reward 92.624542.\n",
      "World Perf: Episode 520.000000. Reward 49.000000. action: 1.000000. mean reward 91.403008.\n",
      "World Perf: Episode 523.000000. Reward 70.000000. action: 1.000000. mean reward 92.901283.\n",
      "World Perf: Episode 526.000000. Reward 95.333333. action: 1.000000. mean reward 93.961121.\n",
      "World Perf: Episode 529.000000. Reward 147.666667. action: 0.000000. mean reward 94.231392.\n",
      "World Perf: Episode 532.000000. Reward 75.333333. action: 1.000000. mean reward 93.520226.\n",
      "World Perf: Episode 535.000000. Reward 113.333333. action: 1.000000. mean reward 92.969910.\n",
      "World Perf: Episode 538.000000. Reward 94.666667. action: 0.000000. mean reward 92.230591.\n",
      "World Perf: Episode 541.000000. Reward 90.333333. action: 1.000000. mean reward 93.082428.\n",
      "World Perf: Episode 544.000000. Reward 63.333333. action: 0.000000. mean reward 96.241280.\n",
      "World Perf: Episode 547.000000. Reward 99.666667. action: 1.000000. mean reward 95.579475.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "World Perf: Episode 550.000000. Reward 78.000000. action: 1.000000. mean reward 96.612602.\n",
      "World Perf: Episode 553.000000. Reward 58.333333. action: 0.000000. mean reward 97.127899.\n",
      "World Perf: Episode 556.000000. Reward 29.666667. action: 1.000000. mean reward 95.638702.\n",
      "World Perf: Episode 559.000000. Reward 75.333333. action: 0.000000. mean reward 94.578606.\n",
      "World Perf: Episode 562.000000. Reward 61.333333. action: 0.000000. mean reward 95.127998.\n",
      "World Perf: Episode 565.000000. Reward 99.000000. action: 0.000000. mean reward 94.564445.\n",
      "World Perf: Episode 568.000000. Reward 156.333333. action: 0.000000. mean reward 98.293976.\n",
      "World Perf: Episode 571.000000. Reward 71.000000. action: 0.000000. mean reward 97.272270.\n",
      "World Perf: Episode 574.000000. Reward 56.333333. action: 1.000000. mean reward 97.629791.\n",
      "World Perf: Episode 577.000000. Reward 90.333333. action: 0.000000. mean reward 97.157890.\n",
      "World Perf: Episode 580.000000. Reward 130.666667. action: 1.000000. mean reward 97.525505.\n",
      "World Perf: Episode 583.000000. Reward 118.333333. action: 1.000000. mean reward 97.117317.\n",
      "World Perf: Episode 586.000000. Reward 63.333333. action: 0.000000. mean reward 96.953606.\n",
      "World Perf: Episode 589.000000. Reward 79.666667. action: 1.000000. mean reward 102.394737.\n",
      "World Perf: Episode 592.000000. Reward 58.000000. action: 1.000000. mean reward 102.169228.\n",
      "World Perf: Episode 595.000000. Reward 47.333333. action: 1.000000. mean reward 100.822968.\n",
      "World Perf: Episode 598.000000. Reward 64.333333. action: 1.000000. mean reward 102.300728.\n",
      "World Perf: Episode 601.000000. Reward 59.333333. action: 0.000000. mean reward 100.982414.\n",
      "World Perf: Episode 604.000000. Reward 63.000000. action: 0.000000. mean reward 99.812622.\n",
      "World Perf: Episode 607.000000. Reward 111.666667. action: 0.000000. mean reward 99.123161.\n",
      "World Perf: Episode 610.000000. Reward 47.333333. action: 1.000000. mean reward 98.012306.\n",
      "World Perf: Episode 613.000000. Reward 134.666667. action: 1.000000. mean reward 98.301170.\n",
      "World Perf: Episode 616.000000. Reward 131.000000. action: 1.000000. mean reward 102.601898.\n",
      "World Perf: Episode 619.000000. Reward 81.666667. action: 1.000000. mean reward 101.643028.\n",
      "World Perf: Episode 622.000000. Reward 65.000000. action: 1.000000. mean reward 100.371216.\n",
      "World Perf: Episode 625.000000. Reward 104.333333. action: 0.000000. mean reward 99.598610.\n",
      "World Perf: Episode 628.000000. Reward 56.666667. action: 0.000000. mean reward 101.781898.\n",
      "World Perf: Episode 631.000000. Reward 43.000000. action: 0.000000. mean reward 100.266060.\n",
      "World Perf: Episode 634.000000. Reward 74.666667. action: 0.000000. mean reward 99.313751.\n",
      "World Perf: Episode 637.000000. Reward 69.333333. action: 0.000000. mean reward 98.264931.\n",
      "World Perf: Episode 640.000000. Reward 87.000000. action: 0.000000. mean reward 100.036934.\n",
      "World Perf: Episode 643.000000. Reward 39.333333. action: 1.000000. mean reward 98.972633.\n",
      "World Perf: Episode 646.000000. Reward 135.000000. action: 0.000000. mean reward 102.063660.\n",
      "World Perf: Episode 649.000000. Reward 114.333333. action: 1.000000. mean reward 104.062561.\n",
      "World Perf: Episode 652.000000. Reward 79.666667. action: 0.000000. mean reward 103.589691.\n",
      "World Perf: Episode 655.000000. Reward 74.666667. action: 1.000000. mean reward 102.743202.\n",
      "World Perf: Episode 658.000000. Reward 97.000000. action: 0.000000. mean reward 104.701141.\n",
      "World Perf: Episode 661.000000. Reward 65.333333. action: 1.000000. mean reward 103.455841.\n",
      "World Perf: Episode 664.000000. Reward 110.000000. action: 1.000000. mean reward 104.644348.\n",
      "World Perf: Episode 667.000000. Reward 151.333333. action: 1.000000. mean reward 107.223976.\n",
      "World Perf: Episode 670.000000. Reward 107.333333. action: 0.000000. mean reward 106.474098.\n",
      "World Perf: Episode 673.000000. Reward 90.333333. action: 0.000000. mean reward 105.488136.\n",
      "World Perf: Episode 676.000000. Reward 118.333333. action: 1.000000. mean reward 107.619110.\n",
      "World Perf: Episode 679.000000. Reward 149.333333. action: 1.000000. mean reward 107.520424.\n",
      "World Perf: Episode 682.000000. Reward 84.666667. action: 0.000000. mean reward 106.650238.\n",
      "World Perf: Episode 685.000000. Reward 124.666667. action: 1.000000. mean reward 106.732262.\n",
      "World Perf: Episode 688.000000. Reward 104.000000. action: 1.000000. mean reward 106.518921.\n",
      "World Perf: Episode 691.000000. Reward 120.000000. action: 0.000000. mean reward 105.920326.\n",
      "World Perf: Episode 694.000000. Reward 112.333333. action: 1.000000. mean reward 105.131203.\n",
      "World Perf: Episode 697.000000. Reward 133.666667. action: 1.000000. mean reward 104.509911.\n",
      "World Perf: Episode 700.000000. Reward 148.666667. action: 1.000000. mean reward 104.461876.\n",
      "World Perf: Episode 703.000000. Reward 163.333333. action: 0.000000. mean reward 104.462807.\n",
      "World Perf: Episode 706.000000. Reward 118.333333. action: 1.000000. mean reward 106.784912.\n",
      "World Perf: Episode 709.000000. Reward 137.000000. action: 0.000000. mean reward 107.669952.\n",
      "World Perf: Episode 712.000000. Reward 51.333333. action: 0.000000. mean reward 107.419891.\n",
      "World Perf: Episode 715.000000. Reward 170.000000. action: 1.000000. mean reward 107.428276.\n",
      "World Perf: Episode 718.000000. Reward 126.000000. action: 1.000000. mean reward 109.513283.\n",
      "World Perf: Episode 721.000000. Reward 122.000000. action: 0.000000. mean reward 108.864197.\n",
      "World Perf: Episode 724.000000. Reward 173.000000. action: 0.000000. mean reward 108.643219.\n",
      "World Perf: Episode 727.000000. Reward 126.000000. action: 0.000000. mean reward 107.911461.\n",
      "World Perf: Episode 730.000000. Reward 125.000000. action: 0.000000. mean reward 107.237099.\n",
      "World Perf: Episode 733.000000. Reward 162.333333. action: 0.000000. mean reward 107.227959.\n",
      "World Perf: Episode 736.000000. Reward 96.333333. action: 1.000000. mean reward 108.508308.\n",
      "World Perf: Episode 739.000000. Reward 101.666667. action: 1.000000. mean reward 109.055595.\n",
      "World Perf: Episode 742.000000. Reward 121.000000. action: 1.000000. mean reward 108.502205.\n",
      "World Perf: Episode 745.000000. Reward 149.666667. action: 0.000000. mean reward 108.311707.\n",
      "World Perf: Episode 748.000000. Reward 120.333333. action: 1.000000. mean reward 107.499237.\n",
      "World Perf: Episode 751.000000. Reward 170.333333. action: 1.000000. mean reward 109.235115.\n",
      "World Perf: Episode 754.000000. Reward 119.000000. action: 1.000000. mean reward 112.163170.\n",
      "World Perf: Episode 757.000000. Reward 130.333333. action: 1.000000. mean reward 111.342705.\n",
      "World Perf: Episode 760.000000. Reward 98.333333. action: 0.000000. mean reward 111.080841.\n",
      "World Perf: Episode 763.000000. Reward 160.666667. action: 0.000000. mean reward 110.992928.\n",
      "World Perf: Episode 766.000000. Reward 95.666667. action: 0.000000. mean reward 110.153809.\n",
      "World Perf: Episode 769.000000. Reward 145.333333. action: 0.000000. mean reward 109.721916.\n",
      "World Perf: Episode 772.000000. Reward 126.000000. action: 0.000000. mean reward 109.141479.\n",
      "World Perf: Episode 775.000000. Reward 143.333333. action: 0.000000. mean reward 108.684135.\n",
      "World Perf: Episode 778.000000. Reward 160.666667. action: 0.000000. mean reward 109.446747.\n",
      "World Perf: Episode 781.000000. Reward 143.000000. action: 1.000000. mean reward 109.015556.\n",
      "World Perf: Episode 784.000000. Reward 194.666667. action: 0.000000. mean reward 109.027580.\n",
      "World Perf: Episode 787.000000. Reward 131.000000. action: 0.000000. mean reward 110.370491.\n",
      "World Perf: Episode 790.000000. Reward 53.000000. action: 0.000000. mean reward 108.816414.\n",
      "World Perf: Episode 793.000000. Reward 131.333333. action: 0.000000. mean reward 108.564949.\n",
      "World Perf: Episode 796.000000. Reward 136.666667. action: 0.000000. mean reward 108.002220.\n",
      "World Perf: Episode 799.000000. Reward 192.666667. action: 0.000000. mean reward 108.625244.\n",
      "World Perf: Episode 802.000000. Reward 200.000000. action: 0.000000. mean reward 108.864632.\n",
      "World Perf: Episode 805.000000. Reward 110.000000. action: 0.000000. mean reward 112.041740.\n",
      "World Perf: Episode 808.000000. Reward 182.666667. action: 1.000000. mean reward 112.675713.\n",
      "World Perf: Episode 811.000000. Reward 200.000000. action: 1.000000. mean reward 115.522797.\n",
      "World Perf: Episode 814.000000. Reward 162.333333. action: 1.000000. mean reward 117.157768.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "World Perf: Episode 817.000000. Reward 182.000000. action: 1.000000. mean reward 119.735588.\n",
      "World Perf: Episode 820.000000. Reward 115.000000. action: 0.000000. mean reward 118.979057.\n",
      "World Perf: Episode 823.000000. Reward 192.000000. action: 0.000000. mean reward 118.919952.\n",
      "World Perf: Episode 826.000000. Reward 184.333333. action: 1.000000. mean reward 118.788994.\n",
      "World Perf: Episode 829.000000. Reward 200.000000. action: 0.000000. mean reward 120.588745.\n",
      "World Perf: Episode 832.000000. Reward 191.666667. action: 1.000000. mean reward 123.249046.\n",
      "World Perf: Episode 835.000000. Reward 161.333333. action: 0.000000. mean reward 124.570290.\n",
      "World Perf: Episode 838.000000. Reward 129.000000. action: 0.000000. mean reward 123.598061.\n",
      "World Perf: Episode 841.000000. Reward 121.333333. action: 0.000000. mean reward 122.542999.\n",
      "World Perf: Episode 844.000000. Reward 133.333333. action: 1.000000. mean reward 121.944580.\n",
      "World Perf: Episode 847.000000. Reward 200.000000. action: 0.000000. mean reward 122.137733.\n",
      "World Perf: Episode 850.000000. Reward 152.666667. action: 0.000000. mean reward 121.926247.\n",
      "World Perf: Episode 853.000000. Reward 200.000000. action: 1.000000. mean reward 122.310982.\n",
      "World Perf: Episode 856.000000. Reward 195.000000. action: 0.000000. mean reward 123.013939.\n",
      "World Perf: Episode 859.000000. Reward 156.666667. action: 0.000000. mean reward 122.322693.\n",
      "World Perf: Episode 862.000000. Reward 137.666667. action: 0.000000. mean reward 124.386879.\n",
      "World Perf: Episode 865.000000. Reward 136.333333. action: 0.000000. mean reward 124.419762.\n",
      "World Perf: Episode 868.000000. Reward 177.666667. action: 1.000000. mean reward 123.992195.\n",
      "World Perf: Episode 871.000000. Reward 187.333333. action: 0.000000. mean reward 126.388649.\n",
      "World Perf: Episode 874.000000. Reward 175.666667. action: 1.000000. mean reward 127.955444.\n",
      "World Perf: Episode 877.000000. Reward 164.666667. action: 1.000000. mean reward 127.415779.\n",
      "World Perf: Episode 880.000000. Reward 143.000000. action: 0.000000. mean reward 126.874886.\n",
      "World Perf: Episode 883.000000. Reward 167.666667. action: 1.000000. mean reward 126.429962.\n",
      "World Perf: Episode 886.000000. Reward 177.666667. action: 0.000000. mean reward 128.194519.\n",
      "World Perf: Episode 889.000000. Reward 160.000000. action: 0.000000. mean reward 127.443428.\n",
      "World Perf: Episode 892.000000. Reward 166.333333. action: 0.000000. mean reward 127.090576.\n",
      "World Perf: Episode 895.000000. Reward 153.000000. action: 0.000000. mean reward 126.491844.\n",
      "World Perf: Episode 898.000000. Reward 146.000000. action: 1.000000. mean reward 127.428261.\n",
      "World Perf: Episode 901.000000. Reward 155.666667. action: 0.000000. mean reward 129.468918.\n",
      "World Perf: Episode 904.000000. Reward 194.333333. action: 0.000000. mean reward 130.725021.\n",
      "World Perf: Episode 907.000000. Reward 149.000000. action: 0.000000. mean reward 131.735672.\n",
      "World Perf: Episode 910.000000. Reward 171.666667. action: 1.000000. mean reward 130.970398.\n",
      "World Perf: Episode 913.000000. Reward 198.000000. action: 1.000000. mean reward 130.471375.\n",
      "World Perf: Episode 916.000000. Reward 138.000000. action: 0.000000. mean reward 129.581192.\n",
      "World Perf: Episode 919.000000. Reward 198.333333. action: 1.000000. mean reward 129.481003.\n",
      "World Perf: Episode 922.000000. Reward 184.333333. action: 1.000000. mean reward 131.745285.\n",
      "World Perf: Episode 925.000000. Reward 175.333333. action: 0.000000. mean reward 131.299637.\n",
      "World Perf: Episode 928.000000. Reward 135.666667. action: 1.000000. mean reward 130.242401.\n",
      "World Perf: Episode 931.000000. Reward 173.333333. action: 0.000000. mean reward 130.890350.\n",
      "World Perf: Episode 934.000000. Reward 171.000000. action: 0.000000. mean reward 132.447586.\n",
      "World Perf: Episode 937.000000. Reward 175.666667. action: 1.000000. mean reward 131.755875.\n",
      "World Perf: Episode 940.000000. Reward 180.333333. action: 1.000000. mean reward 135.527817.\n",
      "World Perf: Episode 943.000000. Reward 182.666667. action: 0.000000. mean reward 141.027512.\n",
      "World Perf: Episode 946.000000. Reward 193.333333. action: 1.000000. mean reward 142.149551.\n",
      "World Perf: Episode 949.000000. Reward 174.666667. action: 0.000000. mean reward 141.460037.\n",
      "World Perf: Episode 952.000000. Reward 188.000000. action: 0.000000. mean reward 147.180420.\n",
      "World Perf: Episode 955.000000. Reward 186.666667. action: 1.000000. mean reward 153.080780.\n",
      "World Perf: Episode 958.000000. Reward 180.666667. action: 0.000000. mean reward 159.764923.\n",
      "World Perf: Episode 961.000000. Reward 195.333333. action: 1.000000. mean reward 162.177414.\n",
      "World Perf: Episode 964.000000. Reward 147.000000. action: 0.000000. mean reward 164.166229.\n",
      "World Perf: Episode 967.000000. Reward 157.666667. action: 0.000000. mean reward 165.377335.\n",
      "World Perf: Episode 970.000000. Reward 156.333333. action: 1.000000. mean reward 163.868439.\n",
      "World Perf: Episode 973.000000. Reward 196.000000. action: 0.000000. mean reward 166.178421.\n",
      "World Perf: Episode 976.000000. Reward 193.333333. action: 0.000000. mean reward 168.191467.\n",
      "World Perf: Episode 979.000000. Reward 200.000000. action: 1.000000. mean reward 167.070663.\n",
      "World Perf: Episode 982.000000. Reward 143.000000. action: 1.000000. mean reward 166.186569.\n",
      "World Perf: Episode 985.000000. Reward 171.666667. action: 1.000000. mean reward 166.941483.\n",
      "World Perf: Episode 988.000000. Reward 195.333333. action: 1.000000. mean reward 168.552246.\n",
      "World Perf: Episode 991.000000. Reward 191.333333. action: 0.000000. mean reward 170.098312.\n",
      "World Perf: Episode 994.000000. Reward 179.666667. action: 1.000000. mean reward 171.595383.\n",
      "World Perf: Episode 997.000000. Reward 149.666667. action: 0.000000. mean reward 172.693253.\n",
      "World Perf: Episode 1000.000000. Reward 182.666667. action: 0.000000. mean reward 173.481033.\n",
      "World Perf: Episode 1003.000000. Reward 188.666667. action: 0.000000. mean reward 174.952591.\n",
      "World Perf: Episode 1006.000000. Reward 196.666667. action: 0.000000. mean reward 173.622314.\n",
      "World Perf: Episode 1009.000000. Reward 125.666667. action: 1.000000. mean reward 172.497925.\n",
      "World Perf: Episode 1012.000000. Reward 152.000000. action: 1.000000. mean reward 173.492294.\n",
      "World Perf: Episode 1015.000000. Reward 179.333333. action: 0.000000. mean reward 174.277756.\n",
      "World Perf: Episode 1018.000000. Reward 156.333333. action: 0.000000. mean reward 172.857620.\n",
      "World Perf: Episode 1021.000000. Reward 173.666667. action: 1.000000. mean reward 173.220047.\n",
      "World Perf: Episode 1024.000000. Reward 172.333333. action: 1.000000. mean reward 172.208191.\n",
      "World Perf: Episode 1027.000000. Reward 185.000000. action: 0.000000. mean reward 170.940918.\n",
      "World Perf: Episode 1030.000000. Reward 197.000000. action: 1.000000. mean reward 170.385757.\n",
      "World Perf: Episode 1033.000000. Reward 182.000000. action: 0.000000. mean reward 171.893982.\n",
      "World Perf: Episode 1036.000000. Reward 168.333333. action: 1.000000. mean reward 171.151474.\n",
      "World Perf: Episode 1039.000000. Reward 184.333333. action: 1.000000. mean reward 170.129166.\n",
      "World Perf: Episode 1042.000000. Reward 187.333333. action: 0.000000. mean reward 171.802429.\n",
      "World Perf: Episode 1045.000000. Reward 176.000000. action: 1.000000. mean reward 172.940353.\n",
      "World Perf: Episode 1048.000000. Reward 186.333333. action: 1.000000. mean reward 173.025101.\n",
      "World Perf: Episode 1051.000000. Reward 188.333333. action: 1.000000. mean reward 171.897202.\n",
      "World Perf: Episode 1054.000000. Reward 190.333333. action: 0.000000. mean reward 172.377625.\n",
      "World Perf: Episode 1057.000000. Reward 190.666667. action: 0.000000. mean reward 172.119003.\n",
      "World Perf: Episode 1060.000000. Reward 200.000000. action: 0.000000. mean reward 173.799210.\n",
      "World Perf: Episode 1063.000000. Reward 200.000000. action: 0.000000. mean reward 172.495560.\n",
      "World Perf: Episode 1066.000000. Reward 185.333333. action: 1.000000. mean reward 173.955917.\n",
      "World Perf: Episode 1069.000000. Reward 200.000000. action: 1.000000. mean reward 172.894180.\n",
      "World Perf: Episode 1072.000000. Reward 186.000000. action: 0.000000. mean reward 174.503296.\n",
      "World Perf: Episode 1075.000000. Reward 188.000000. action: 1.000000. mean reward 174.567703.\n",
      "World Perf: Episode 1078.000000. Reward 173.666667. action: 1.000000. mean reward 173.962662.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "World Perf: Episode 1081.000000. Reward 164.333333. action: 0.000000. mean reward 172.898453.\n",
      "World Perf: Episode 1084.000000. Reward 190.000000. action: 0.000000. mean reward 171.740707.\n",
      "World Perf: Episode 1087.000000. Reward 195.000000. action: 1.000000. mean reward 171.221420.\n",
      "World Perf: Episode 1090.000000. Reward 197.333333. action: 0.000000. mean reward 170.145401.\n",
      "World Perf: Episode 1093.000000. Reward 143.000000. action: 1.000000. mean reward 168.568710.\n",
      "World Perf: Episode 1096.000000. Reward 189.000000. action: 1.000000. mean reward 168.154190.\n",
      "World Perf: Episode 1099.000000. Reward 189.000000. action: 0.000000. mean reward 169.338806.\n",
      "World Perf: Episode 1102.000000. Reward 200.000000. action: 0.000000. mean reward 168.118484.\n",
      "World Perf: Episode 1105.000000. Reward 197.000000. action: 0.000000. mean reward 167.172272.\n",
      "World Perf: Episode 1108.000000. Reward 175.333333. action: 0.000000. mean reward 166.429001.\n",
      "World Perf: Episode 1111.000000. Reward 200.000000. action: 0.000000. mean reward 167.268860.\n",
      "World Perf: Episode 1114.000000. Reward 196.333333. action: 1.000000. mean reward 169.047729.\n",
      "World Perf: Episode 1117.000000. Reward 182.333333. action: 1.000000. mean reward 167.866409.\n",
      "World Perf: Episode 1120.000000. Reward 185.666667. action: 0.000000. mean reward 167.698318.\n",
      "World Perf: Episode 1123.000000. Reward 200.000000. action: 0.000000. mean reward 167.576645.\n",
      "World Perf: Episode 1126.000000. Reward 177.333333. action: 1.000000. mean reward 166.275528.\n",
      "World Perf: Episode 1129.000000. Reward 200.000000. action: 0.000000. mean reward 166.482941.\n",
      "World Perf: Episode 1132.000000. Reward 153.000000. action: 1.000000. mean reward 166.924347.\n",
      "World Perf: Episode 1135.000000. Reward 179.666667. action: 0.000000. mean reward 165.515732.\n",
      "World Perf: Episode 1138.000000. Reward 181.666667. action: 0.000000. mean reward 164.404037.\n",
      "World Perf: Episode 1141.000000. Reward 156.666667. action: 0.000000. mean reward 163.399994.\n",
      "World Perf: Episode 1144.000000. Reward 178.333333. action: 0.000000. mean reward 162.586197.\n",
      "World Perf: Episode 1147.000000. Reward 200.000000. action: 1.000000. mean reward 161.443100.\n",
      "World Perf: Episode 1150.000000. Reward 168.666667. action: 1.000000. mean reward 160.597763.\n",
      "World Perf: Episode 1153.000000. Reward 151.333333. action: 1.000000. mean reward 159.184845.\n",
      "World Perf: Episode 1156.000000. Reward 199.666667. action: 1.000000. mean reward 158.948410.\n",
      "World Perf: Episode 1159.000000. Reward 162.666667. action: 1.000000. mean reward 157.732010.\n",
      "World Perf: Episode 1162.000000. Reward 185.000000. action: 0.000000. mean reward 156.847885.\n",
      "World Perf: Episode 1165.000000. Reward 171.666667. action: 1.000000. mean reward 156.783676.\n",
      "World Perf: Episode 1168.000000. Reward 194.333333. action: 1.000000. mean reward 158.541534.\n",
      "World Perf: Episode 1171.000000. Reward 166.333333. action: 1.000000. mean reward 157.255096.\n",
      "World Perf: Episode 1174.000000. Reward 200.000000. action: 0.000000. mean reward 156.527618.\n",
      "World Perf: Episode 1177.000000. Reward 166.000000. action: 0.000000. mean reward 155.699982.\n",
      "World Perf: Episode 1180.000000. Reward 200.000000. action: 1.000000. mean reward 154.735016.\n",
      "World Perf: Episode 1183.000000. Reward 200.000000. action: 0.000000. mean reward 156.689819.\n",
      "World Perf: Episode 1186.000000. Reward 200.000000. action: 1.000000. mean reward 158.641800.\n",
      "World Perf: Episode 1189.000000. Reward 185.666667. action: 1.000000. mean reward 158.465393.\n",
      "World Perf: Episode 1192.000000. Reward 200.000000. action: 1.000000. mean reward 157.627899.\n",
      "World Perf: Episode 1195.000000. Reward 200.000000. action: 0.000000. mean reward 156.666489.\n",
      "World Perf: Episode 1198.000000. Reward 186.333333. action: 0.000000. mean reward 158.476746.\n",
      "World Perf: Episode 1201.000000. Reward 156.000000. action: 0.000000. mean reward 157.109009.\n",
      "World Perf: Episode 1204.000000. Reward 197.333333. action: 1.000000. mean reward 158.862381.\n",
      "World Perf: Episode 1207.000000. Reward 200.000000. action: 1.000000. mean reward 158.069229.\n",
      "World Perf: Episode 1210.000000. Reward 185.000000. action: 1.000000. mean reward 156.967575.\n",
      "World Perf: Episode 1213.000000. Reward 198.666667. action: 0.000000. mean reward 157.200562.\n",
      "World Perf: Episode 1216.000000. Reward 139.666667. action: 0.000000. mean reward 155.777069.\n",
      "World Perf: Episode 1219.000000. Reward 200.000000. action: 1.000000. mean reward 155.956741.\n",
      "World Perf: Episode 1222.000000. Reward 198.666667. action: 1.000000. mean reward 156.870880.\n",
      "World Perf: Episode 1225.000000. Reward 194.333333. action: 1.000000. mean reward 157.693008.\n",
      "World Perf: Episode 1228.000000. Reward 182.666667. action: 0.000000. mean reward 156.520981.\n",
      "World Perf: Episode 1231.000000. Reward 174.000000. action: 1.000000. mean reward 156.192673.\n",
      "World Perf: Episode 1234.000000. Reward 200.000000. action: 0.000000. mean reward 157.059311.\n",
      "World Perf: Episode 1237.000000. Reward 200.000000. action: 0.000000. mean reward 156.028824.\n",
      "World Perf: Episode 1240.000000. Reward 200.000000. action: 0.000000. mean reward 155.283829.\n",
      "World Perf: Episode 1243.000000. Reward 200.000000. action: 0.000000. mean reward 154.424423.\n",
      "World Perf: Episode 1246.000000. Reward 172.000000. action: 0.000000. mean reward 153.203323.\n",
      "World Perf: Episode 1249.000000. Reward 188.000000. action: 1.000000. mean reward 152.723450.\n",
      "World Perf: Episode 1252.000000. Reward 176.666667. action: 0.000000. mean reward 151.609238.\n",
      "World Perf: Episode 1255.000000. Reward 185.000000. action: 1.000000. mean reward 153.266983.\n",
      "World Perf: Episode 1258.000000. Reward 183.000000. action: 1.000000. mean reward 154.200836.\n",
      "World Perf: Episode 1261.000000. Reward 172.333333. action: 1.000000. mean reward 153.062378.\n",
      "World Perf: Episode 1264.000000. Reward 162.666667. action: 0.000000. mean reward 151.915207.\n",
      "World Perf: Episode 1267.000000. Reward 184.000000. action: 1.000000. mean reward 150.819977.\n",
      "World Perf: Episode 1270.000000. Reward 200.000000. action: 1.000000. mean reward 152.901382.\n",
      "World Perf: Episode 1273.000000. Reward 200.000000. action: 1.000000. mean reward 152.804611.\n",
      "World Perf: Episode 1276.000000. Reward 152.666667. action: 0.000000. mean reward 151.926620.\n",
      "World Perf: Episode 1279.000000. Reward 188.666667. action: 0.000000. mean reward 151.086990.\n",
      "World Perf: Episode 1282.000000. Reward 200.000000. action: 1.000000. mean reward 150.559372.\n",
      "World Perf: Episode 1285.000000. Reward 200.000000. action: 0.000000. mean reward 151.660568.\n",
      "World Perf: Episode 1288.000000. Reward 193.000000. action: 0.000000. mean reward 150.747879.\n",
      "World Perf: Episode 1291.000000. Reward 183.666667. action: 0.000000. mean reward 149.844315.\n",
      "World Perf: Episode 1294.000000. Reward 200.000000. action: 0.000000. mean reward 149.146271.\n",
      "World Perf: Episode 1297.000000. Reward 193.666667. action: 1.000000. mean reward 151.091934.\n",
      "World Perf: Episode 1300.000000. Reward 169.333333. action: 0.000000. mean reward 150.196350.\n",
      "World Perf: Episode 1303.000000. Reward 200.000000. action: 0.000000. mean reward 149.787308.\n",
      "World Perf: Episode 1306.000000. Reward 176.666667. action: 1.000000. mean reward 149.482071.\n",
      "World Perf: Episode 1309.000000. Reward 199.333333. action: 0.000000. mean reward 148.952774.\n",
      "World Perf: Episode 1312.000000. Reward 189.333333. action: 1.000000. mean reward 149.649750.\n",
      "World Perf: Episode 1315.000000. Reward 177.666667. action: 1.000000. mean reward 151.228928.\n",
      "World Perf: Episode 1318.000000. Reward 200.000000. action: 1.000000. mean reward 152.269775.\n",
      "World Perf: Episode 1321.000000. Reward 200.000000. action: 0.000000. mean reward 153.259964.\n",
      "World Perf: Episode 1324.000000. Reward 200.000000. action: 0.000000. mean reward 154.304398.\n",
      "World Perf: Episode 1327.000000. Reward 172.666667. action: 1.000000. mean reward 153.435150.\n",
      "World Perf: Episode 1330.000000. Reward 187.333333. action: 1.000000. mean reward 155.338547.\n",
      "World Perf: Episode 1333.000000. Reward 200.000000. action: 0.000000. mean reward 157.266312.\n",
      "World Perf: Episode 1336.000000. Reward 200.000000. action: 0.000000. mean reward 156.327347.\n",
      "World Perf: Episode 1339.000000. Reward 200.000000. action: 1.000000. mean reward 155.601959.\n",
      "World Perf: Episode 1342.000000. Reward 200.000000. action: 1.000000. mean reward 157.438217.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "World Perf: Episode 1345.000000. Reward 200.000000. action: 1.000000. mean reward 159.265823.\n",
      "World Perf: Episode 1348.000000. Reward 190.666667. action: 1.000000. mean reward 160.089203.\n",
      "World Perf: Episode 1351.000000. Reward 200.000000. action: 1.000000. mean reward 160.980164.\n",
      "World Perf: Episode 1354.000000. Reward 200.000000. action: 1.000000. mean reward 162.696915.\n",
      "World Perf: Episode 1357.000000. Reward 200.000000. action: 1.000000. mean reward 164.400925.\n",
      "World Perf: Episode 1360.000000. Reward 200.000000. action: 0.000000. mean reward 163.960403.\n",
      "World Perf: Episode 1363.000000. Reward 195.666667. action: 0.000000. mean reward 165.594254.\n",
      "World Perf: Episode 1366.000000. Reward 200.000000. action: 0.000000. mean reward 167.272720.\n",
      "World Perf: Episode 1369.000000. Reward 200.000000. action: 0.000000. mean reward 168.916077.\n",
      "World Perf: Episode 1372.000000. Reward 200.000000. action: 1.000000. mean reward 170.584641.\n",
      "World Perf: Episode 1375.000000. Reward 200.000000. action: 1.000000. mean reward 169.820908.\n",
      "World Perf: Episode 1378.000000. Reward 200.000000. action: 1.000000. mean reward 171.614822.\n",
      "World Perf: Episode 1381.000000. Reward 192.333333. action: 1.000000. mean reward 172.042404.\n",
      "World Perf: Episode 1384.000000. Reward 188.000000. action: 0.000000. mean reward 171.959229.\n",
      "World Perf: Episode 1387.000000. Reward 200.000000. action: 1.000000. mean reward 173.514694.\n",
      "World Perf: Episode 1390.000000. Reward 200.000000. action: 1.000000. mean reward 173.685303.\n",
      "World Perf: Episode 1393.000000. Reward 200.000000. action: 0.000000. mean reward 174.330795.\n",
      "World Perf: Episode 1396.000000. Reward 200.000000. action: 1.000000. mean reward 175.003967.\n",
      "World Perf: Episode 1399.000000. Reward 200.000000. action: 0.000000. mean reward 175.722717.\n",
      "World Perf: Episode 1402.000000. Reward 200.000000. action: 0.000000. mean reward 177.118973.\n",
      "World Perf: Episode 1405.000000. Reward 200.000000. action: 0.000000. mean reward 176.932068.\n",
      "World Perf: Episode 1408.000000. Reward 200.000000. action: 0.000000. mean reward 178.576736.\n",
      "World Perf: Episode 1411.000000. Reward 200.000000. action: 1.000000. mean reward 179.998978.\n",
      "World Perf: Episode 1414.000000. Reward 200.000000. action: 0.000000. mean reward 179.914551.\n",
      "World Perf: Episode 1417.000000. Reward 191.666667. action: 0.000000. mean reward 181.353561.\n",
      "World Perf: Episode 1420.000000. Reward 200.000000. action: 1.000000. mean reward 181.771255.\n",
      "World Perf: Episode 1423.000000. Reward 200.000000. action: 0.000000. mean reward 182.488510.\n",
      "World Perf: Episode 1426.000000. Reward 200.000000. action: 0.000000. mean reward 183.795578.\n",
      "World Perf: Episode 1429.000000. Reward 194.666667. action: 0.000000. mean reward 185.059250.\n",
      "World Perf: Episode 1432.000000. Reward 200.000000. action: 0.000000. mean reward 186.304565.\n",
      "World Perf: Episode 1435.000000. Reward 200.000000. action: 0.000000. mean reward 187.386612.\n",
      "World Perf: Episode 1438.000000. Reward 200.000000. action: 0.000000. mean reward 188.738998.\n",
      "World Perf: Episode 1441.000000. Reward 200.000000. action: 1.000000. mean reward 188.118774.\n",
      "World Perf: Episode 1444.000000. Reward 194.333333. action: 1.000000. mean reward 189.418213.\n",
      "World Perf: Episode 1447.000000. Reward 193.000000. action: 0.000000. mean reward 189.882492.\n",
      "World Perf: Episode 1450.000000. Reward 200.000000. action: 1.000000. mean reward 191.273392.\n",
      "World Perf: Episode 1453.000000. Reward 190.000000. action: 1.000000. mean reward 192.365295.\n",
      "World Perf: Episode 1456.000000. Reward 200.000000. action: 0.000000. mean reward 193.564835.\n",
      "World Perf: Episode 1459.000000. Reward 200.000000. action: 1.000000. mean reward 194.469116.\n",
      "World Perf: Episode 1462.000000. Reward 200.000000. action: 1.000000. mean reward 193.889175.\n",
      "World Perf: Episode 1465.000000. Reward 200.000000. action: 1.000000. mean reward 194.980148.\n",
      "World Perf: Episode 1468.000000. Reward 200.000000. action: 0.000000. mean reward 196.174500.\n",
      "World Perf: Episode 1471.000000. Reward 200.000000. action: 0.000000. mean reward 194.686295.\n",
      "World Perf: Episode 1474.000000. Reward 186.666667. action: 0.000000. mean reward 194.158020.\n",
      "World Perf: Episode 1477.000000. Reward 200.000000. action: 0.000000. mean reward 193.720505.\n",
      "World Perf: Episode 1480.000000. Reward 200.000000. action: 1.000000. mean reward 192.691040.\n",
      "World Perf: Episode 1483.000000. Reward 192.666667. action: 1.000000. mean reward 193.764664.\n",
      "World Perf: Episode 1486.000000. Reward 200.000000. action: 1.000000. mean reward 193.213913.\n",
      "World Perf: Episode 1489.000000. Reward 200.000000. action: 0.000000. mean reward 194.173172.\n",
      "World Perf: Episode 1492.000000. Reward 200.000000. action: 0.000000. mean reward 194.414963.\n",
      "World Perf: Episode 1495.000000. Reward 200.000000. action: 1.000000. mean reward 194.609619.\n",
      "World Perf: Episode 1498.000000. Reward 200.000000. action: 1.000000. mean reward 195.411087.\n",
      "World Perf: Episode 1501.000000. Reward 200.000000. action: 0.000000. mean reward 196.468384.\n",
      "World Perf: Episode 1504.000000. Reward 200.000000. action: 0.000000. mean reward 195.343307.\n",
      "World Perf: Episode 1507.000000. Reward 200.000000. action: 1.000000. mean reward 196.298080.\n",
      "World Perf: Episode 1510.000000. Reward 200.000000. action: 0.000000. mean reward 196.432068.\n",
      "World Perf: Episode 1513.000000. Reward 185.000000. action: 0.000000. mean reward 197.286911.\n",
      "World Perf: Episode 1516.000000. Reward 200.000000. action: 1.000000. mean reward 197.025620.\n",
      "World Perf: Episode 1519.000000. Reward 200.000000. action: 1.000000. mean reward 198.093979.\n",
      "World Perf: Episode 1522.000000. Reward 200.000000. action: 0.000000. mean reward 198.722916.\n",
      "World Perf: Episode 1525.000000. Reward 200.000000. action: 0.000000. mean reward 197.466263.\n",
      "World Perf: Episode 1528.000000. Reward 200.000000. action: 0.000000. mean reward 197.814270.\n",
      "World Perf: Episode 1531.000000. Reward 189.333333. action: 0.000000. mean reward 198.723755.\n",
      "World Perf: Episode 1534.000000. Reward 200.000000. action: 0.000000. mean reward 199.792679.\n",
      "World Perf: Episode 1537.000000. Reward 200.000000. action: 0.000000. mean reward 200.768234.\n",
      "World Perf: Episode 1540.000000. Reward 200.000000. action: 1.000000. mean reward 201.699539.\n",
      "World Perf: Episode 1543.000000. Reward 200.000000. action: 1.000000. mean reward 202.700867.\n",
      "World Perf: Episode 1546.000000. Reward 200.000000. action: 0.000000. mean reward 201.295227.\n",
      "World Perf: Episode 1549.000000. Reward 200.000000. action: 0.000000. mean reward 201.092941.\n",
      "World Perf: Episode 1552.000000. Reward 200.000000. action: 1.000000. mean reward 199.595108.\n",
      "World Perf: Episode 1555.000000. Reward 200.000000. action: 0.000000. mean reward 200.013962.\n",
      "World Perf: Episode 1558.000000. Reward 200.000000. action: 0.000000. mean reward 199.714218.\n",
      "World Perf: Episode 1561.000000. Reward 200.000000. action: 1.000000. mean reward 198.854691.\n",
      "World Perf: Episode 1564.000000. Reward 200.000000. action: 0.000000. mean reward 199.240128.\n",
      "World Perf: Episode 1567.000000. Reward 200.000000. action: 1.000000. mean reward 198.992859.\n",
      "World Perf: Episode 1570.000000. Reward 200.000000. action: 0.000000. mean reward 199.203003.\n",
      "World Perf: Episode 1573.000000. Reward 200.000000. action: 0.000000. mean reward 197.635696.\n",
      "World Perf: Episode 1576.000000. Reward 200.000000. action: 1.000000. mean reward 197.893051.\n",
      "World Perf: Episode 1579.000000. Reward 200.000000. action: 0.000000. mean reward 197.943176.\n",
      "World Perf: Episode 1582.000000. Reward 200.000000. action: 1.000000. mean reward 196.447693.\n",
      "World Perf: Episode 1585.000000. Reward 190.666667. action: 1.000000. mean reward 196.579880.\n",
      "World Perf: Episode 1588.000000. Reward 200.000000. action: 1.000000. mean reward 196.651733.\n",
      "World Perf: Episode 1591.000000. Reward 200.000000. action: 1.000000. mean reward 197.816971.\n",
      "World Perf: Episode 1594.000000. Reward 200.000000. action: 1.000000. mean reward 198.884445.\n",
      "World Perf: Episode 1597.000000. Reward 200.000000. action: 1.000000. mean reward 197.690781.\n",
      "World Perf: Episode 1600.000000. Reward 200.000000. action: 0.000000. mean reward 197.590744.\n",
      "World Perf: Episode 1603.000000. Reward 200.000000. action: 0.000000. mean reward 197.697998.\n",
      "World Perf: Episode 1606.000000. Reward 200.000000. action: 0.000000. mean reward 198.720901.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "World Perf: Episode 1609.000000. Reward 200.000000. action: 0.000000. mean reward 199.730057.\n",
      "World Perf: Episode 1612.000000. Reward 200.000000. action: 1.000000. mean reward 200.725586.\n",
      "World Perf: Episode 1615.000000. Reward 200.000000. action: 0.000000. mean reward 201.677185.\n",
      "World Perf: Episode 1618.000000. Reward 200.000000. action: 1.000000. mean reward 202.628159.\n",
      "World Perf: Episode 1621.000000. Reward 200.000000. action: 1.000000. mean reward 203.595932.\n",
      "World Perf: Episode 1624.000000. Reward 200.000000. action: 0.000000. mean reward 202.858231.\n",
      "World Perf: Episode 1627.000000. Reward 200.000000. action: 1.000000. mean reward 203.839478.\n",
      "World Perf: Episode 1630.000000. Reward 200.000000. action: 0.000000. mean reward 204.760254.\n",
      "World Perf: Episode 1633.000000. Reward 200.000000. action: 1.000000. mean reward 205.619247.\n",
      "World Perf: Episode 1636.000000. Reward 200.000000. action: 1.000000. mean reward 206.559891.\n",
      "World Perf: Episode 1639.000000. Reward 200.000000. action: 1.000000. mean reward 206.930359.\n",
      "World Perf: Episode 1642.000000. Reward 200.000000. action: 1.000000. mean reward 207.509033.\n",
      "World Perf: Episode 1645.000000. Reward 200.000000. action: 0.000000. mean reward 208.321121.\n",
      "World Perf: Episode 1648.000000. Reward 200.000000. action: 0.000000. mean reward 207.359482.\n",
      "World Perf: Episode 1651.000000. Reward 200.000000. action: 0.000000. mean reward 207.729477.\n",
      "World Perf: Episode 1654.000000. Reward 200.000000. action: 0.000000. mean reward 206.012161.\n",
      "World Perf: Episode 1657.000000. Reward 200.000000. action: 0.000000. mean reward 206.959106.\n",
      "World Perf: Episode 1660.000000. Reward 200.000000. action: 0.000000. mean reward 207.657883.\n",
      "World Perf: Episode 1663.000000. Reward 200.000000. action: 1.000000. mean reward 206.115540.\n",
      "World Perf: Episode 1666.000000. Reward 200.000000. action: 1.000000. mean reward 207.030945.\n",
      "World Perf: Episode 1669.000000. Reward 200.000000. action: 1.000000. mean reward 205.449356.\n",
      "World Perf: Episode 1672.000000. Reward 200.000000. action: 0.000000. mean reward 204.651184.\n",
      "World Perf: Episode 1675.000000. Reward 200.000000. action: 1.000000. mean reward 204.968704.\n",
      "World Perf: Episode 1678.000000. Reward 200.000000. action: 1.000000. mean reward 204.898376.\n",
      "World Perf: Episode 1681.000000. Reward 200.000000. action: 0.000000. mean reward 204.801086.\n",
      "World Perf: Episode 1684.000000. Reward 200.000000. action: 1.000000. mean reward 203.020706.\n",
      "World Perf: Episode 1687.000000. Reward 200.000000. action: 0.000000. mean reward 203.986038.\n",
      "World Perf: Episode 1690.000000. Reward 200.000000. action: 0.000000. mean reward 205.038162.\n",
      "World Perf: Episode 1693.000000. Reward 200.000000. action: 0.000000. mean reward 205.921371.\n",
      "World Perf: Episode 1696.000000. Reward 200.000000. action: 1.000000. mean reward 206.119080.\n",
      "World Perf: Episode 1699.000000. Reward 200.000000. action: 0.000000. mean reward 206.211899.\n",
      "World Perf: Episode 1702.000000. Reward 200.000000. action: 0.000000. mean reward 207.565018.\n",
      "World Perf: Episode 1705.000000. Reward 200.000000. action: 0.000000. mean reward 208.590134.\n",
      "World Perf: Episode 1708.000000. Reward 200.000000. action: 1.000000. mean reward 209.565079.\n",
      "World Perf: Episode 1711.000000. Reward 200.000000. action: 0.000000. mean reward 210.653488.\n",
      "World Perf: Episode 1714.000000. Reward 200.000000. action: 1.000000. mean reward 211.413223.\n",
      "World Perf: Episode 1717.000000. Reward 200.000000. action: 0.000000. mean reward 212.229111.\n",
      "World Perf: Episode 1720.000000. Reward 200.000000. action: 1.000000. mean reward 213.187271.\n",
      "World Perf: Episode 1723.000000. Reward 200.000000. action: 0.000000. mean reward 213.941467.\n",
      "World Perf: Episode 1726.000000. Reward 200.000000. action: 0.000000. mean reward 214.721359.\n",
      "World Perf: Episode 1729.000000. Reward 200.000000. action: 1.000000. mean reward 215.452286.\n",
      "World Perf: Episode 1732.000000. Reward 200.000000. action: 1.000000. mean reward 215.535156.\n",
      "World Perf: Episode 1735.000000. Reward 200.000000. action: 0.000000. mean reward 216.743729.\n",
      "World Perf: Episode 1738.000000. Reward 200.000000. action: 0.000000. mean reward 217.279434.\n",
      "World Perf: Episode 1741.000000. Reward 200.000000. action: 1.000000. mean reward 217.939880.\n",
      "World Perf: Episode 1744.000000. Reward 200.000000. action: 1.000000. mean reward 218.707962.\n",
      "World Perf: Episode 1747.000000. Reward 200.000000. action: 0.000000. mean reward 219.342514.\n",
      "World Perf: Episode 1750.000000. Reward 200.000000. action: 1.000000. mean reward 219.998291.\n",
      "World Perf: Episode 1753.000000. Reward 200.000000. action: 1.000000. mean reward 220.573532.\n",
      "World Perf: Episode 1756.000000. Reward 200.000000. action: 1.000000. mean reward 220.916260.\n",
      "World Perf: Episode 1759.000000. Reward 200.000000. action: 0.000000. mean reward 221.692017.\n",
      "World Perf: Episode 1762.000000. Reward 200.000000. action: 1.000000. mean reward 222.598709.\n",
      "World Perf: Episode 1765.000000. Reward 200.000000. action: 0.000000. mean reward 223.151611.\n",
      "World Perf: Episode 1768.000000. Reward 200.000000. action: 0.000000. mean reward 223.123947.\n",
      "World Perf: Episode 1771.000000. Reward 200.000000. action: 1.000000. mean reward 223.711365.\n",
      "World Perf: Episode 1774.000000. Reward 200.000000. action: 1.000000. mean reward 222.360168.\n",
      "World Perf: Episode 1777.000000. Reward 200.000000. action: 1.000000. mean reward 221.005905.\n",
      "World Perf: Episode 1780.000000. Reward 200.000000. action: 0.000000. mean reward 221.611923.\n",
      "World Perf: Episode 1783.000000. Reward 200.000000. action: 0.000000. mean reward 222.230057.\n",
      "World Perf: Episode 1786.000000. Reward 200.000000. action: 0.000000. mean reward 222.913864.\n",
      "World Perf: Episode 1789.000000. Reward 200.000000. action: 1.000000. mean reward 221.392395.\n",
      "World Perf: Episode 1792.000000. Reward 200.000000. action: 0.000000. mean reward 221.101257.\n",
      "World Perf: Episode 1795.000000. Reward 200.000000. action: 1.000000. mean reward 221.052963.\n",
      "World Perf: Episode 1798.000000. Reward 200.000000. action: 0.000000. mean reward 221.235367.\n",
      "World Perf: Episode 1801.000000. Reward 200.000000. action: 1.000000. mean reward 221.876083.\n",
      "World Perf: Episode 1804.000000. Reward 200.000000. action: 0.000000. mean reward 222.462082.\n",
      "World Perf: Episode 1807.000000. Reward 200.000000. action: 0.000000. mean reward 223.075745.\n",
      "World Perf: Episode 1810.000000. Reward 200.000000. action: 1.000000. mean reward 223.639267.\n",
      "World Perf: Episode 1813.000000. Reward 200.000000. action: 0.000000. mean reward 224.298721.\n",
      "World Perf: Episode 1816.000000. Reward 200.000000. action: 1.000000. mean reward 224.025589.\n",
      "World Perf: Episode 1819.000000. Reward 200.000000. action: 1.000000. mean reward 223.543625.\n",
      "World Perf: Episode 1822.000000. Reward 200.000000. action: 1.000000. mean reward 224.071701.\n",
      "World Perf: Episode 1825.000000. Reward 200.000000. action: 0.000000. mean reward 224.584732.\n",
      "World Perf: Episode 1828.000000. Reward 200.000000. action: 1.000000. mean reward 224.289658.\n",
      "World Perf: Episode 1831.000000. Reward 200.000000. action: 0.000000. mean reward 224.770584.\n",
      "World Perf: Episode 1834.000000. Reward 200.000000. action: 0.000000. mean reward 225.499817.\n",
      "World Perf: Episode 1837.000000. Reward 200.000000. action: 1.000000. mean reward 227.313904.\n",
      "World Perf: Episode 1840.000000. Reward 200.000000. action: 1.000000. mean reward 227.677124.\n",
      "World Perf: Episode 1843.000000. Reward 200.000000. action: 0.000000. mean reward 228.050949.\n",
      "World Perf: Episode 1846.000000. Reward 200.000000. action: 1.000000. mean reward 229.759827.\n",
      "World Perf: Episode 1849.000000. Reward 200.000000. action: 1.000000. mean reward 229.780991.\n",
      "World Perf: Episode 1852.000000. Reward 200.000000. action: 0.000000. mean reward 230.339050.\n",
      "World Perf: Episode 1855.000000. Reward 200.000000. action: 0.000000. mean reward 231.001785.\n",
      "World Perf: Episode 1858.000000. Reward 200.000000. action: 0.000000. mean reward 231.388184.\n",
      "World Perf: Episode 1861.000000. Reward 200.000000. action: 1.000000. mean reward 231.282242.\n",
      "World Perf: Episode 1864.000000. Reward 200.000000. action: 1.000000. mean reward 231.717224.\n",
      "World Perf: Episode 1867.000000. Reward 200.000000. action: 0.000000. mean reward 229.874802.\n",
      "World Perf: Episode 1870.000000. Reward 200.000000. action: 0.000000. mean reward 228.714966.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "World Perf: Episode 1873.000000. Reward 200.000000. action: 1.000000. mean reward 229.265152.\n",
      "World Perf: Episode 1876.000000. Reward 200.000000. action: 1.000000. mean reward 227.927322.\n",
      "World Perf: Episode 1879.000000. Reward 200.000000. action: 1.000000. mean reward 228.085999.\n",
      "World Perf: Episode 1882.000000. Reward 200.000000. action: 1.000000. mean reward 228.557480.\n",
      "World Perf: Episode 1885.000000. Reward 200.000000. action: 0.000000. mean reward 228.991928.\n",
      "World Perf: Episode 1888.000000. Reward 200.000000. action: 0.000000. mean reward 229.426559.\n",
      "World Perf: Episode 1891.000000. Reward 200.000000. action: 1.000000. mean reward 229.844727.\n",
      "World Perf: Episode 1894.000000. Reward 200.000000. action: 1.000000. mean reward 230.231079.\n",
      "World Perf: Episode 1897.000000. Reward 200.000000. action: 0.000000. mean reward 230.623642.\n",
      "World Perf: Episode 1900.000000. Reward 200.000000. action: 1.000000. mean reward 230.407211.\n",
      "World Perf: Episode 1903.000000. Reward 200.000000. action: 0.000000. mean reward 230.876785.\n",
      "World Perf: Episode 1906.000000. Reward 200.000000. action: 0.000000. mean reward 231.306381.\n",
      "World Perf: Episode 1909.000000. Reward 200.000000. action: 1.000000. mean reward 230.751389.\n",
      "World Perf: Episode 1912.000000. Reward 200.000000. action: 1.000000. mean reward 229.936462.\n",
      "World Perf: Episode 1915.000000. Reward 200.000000. action: 0.000000. mean reward 230.385147.\n",
      "World Perf: Episode 1918.000000. Reward 200.000000. action: 1.000000. mean reward 229.451004.\n",
      "World Perf: Episode 1921.000000. Reward 200.000000. action: 1.000000. mean reward 229.810226.\n",
      "World Perf: Episode 1924.000000. Reward 200.000000. action: 1.000000. mean reward 230.154678.\n",
      "World Perf: Episode 1927.000000. Reward 200.000000. action: 0.000000. mean reward 230.861160.\n",
      "World Perf: Episode 1930.000000. Reward 200.000000. action: 1.000000. mean reward 229.913223.\n",
      "World Perf: Episode 1933.000000. Reward 200.000000. action: 0.000000. mean reward 230.480972.\n",
      "World Perf: Episode 1936.000000. Reward 200.000000. action: 1.000000. mean reward 228.441589.\n",
      "World Perf: Episode 1939.000000. Reward 200.000000. action: 0.000000. mean reward 229.156921.\n",
      "World Perf: Episode 1942.000000. Reward 200.000000. action: 1.000000. mean reward 229.844833.\n",
      "World Perf: Episode 1945.000000. Reward 200.000000. action: 1.000000. mean reward 227.554504.\n",
      "World Perf: Episode 1948.000000. Reward 200.000000. action: 1.000000. mean reward 228.433426.\n",
      "World Perf: Episode 1951.000000. Reward 200.000000. action: 0.000000. mean reward 226.301529.\n",
      "World Perf: Episode 1954.000000. Reward 200.000000. action: 0.000000. mean reward 226.677261.\n",
      "World Perf: Episode 1957.000000. Reward 200.000000. action: 1.000000. mean reward 227.212448.\n",
      "World Perf: Episode 1960.000000. Reward 200.000000. action: 1.000000. mean reward 227.615463.\n",
      "World Perf: Episode 1963.000000. Reward 200.000000. action: 0.000000. mean reward 228.159241.\n",
      "World Perf: Episode 1966.000000. Reward 200.000000. action: 0.000000. mean reward 228.608337.\n",
      "World Perf: Episode 1969.000000. Reward 200.000000. action: 1.000000. mean reward 228.986618.\n",
      "World Perf: Episode 1972.000000. Reward 200.000000. action: 0.000000. mean reward 226.837723.\n",
      "World Perf: Episode 1975.000000. Reward 200.000000. action: 0.000000. mean reward 227.712509.\n",
      "World Perf: Episode 1978.000000. Reward 200.000000. action: 1.000000. mean reward 227.622208.\n",
      "World Perf: Episode 1981.000000. Reward 200.000000. action: 0.000000. mean reward 228.469360.\n",
      "World Perf: Episode 1984.000000. Reward 200.000000. action: 1.000000. mean reward 229.232376.\n",
      "World Perf: Episode 1987.000000. Reward 200.000000. action: 0.000000. mean reward 229.646301.\n",
      "World Perf: Episode 1990.000000. Reward 200.000000. action: 0.000000. mean reward 230.366531.\n",
      "World Perf: Episode 1993.000000. Reward 200.000000. action: 0.000000. mean reward 230.750000.\n",
      "World Perf: Episode 1996.000000. Reward 200.000000. action: 1.000000. mean reward 231.528503.\n",
      "World Perf: Episode 1999.000000. Reward 200.000000. action: 1.000000. mean reward 232.045517.\n",
      "World Perf: Episode 2002.000000. Reward 200.000000. action: 0.000000. mean reward 232.370789.\n",
      "World Perf: Episode 2005.000000. Reward 200.000000. action: 1.000000. mean reward 232.912643.\n",
      "World Perf: Episode 2008.000000. Reward 200.000000. action: 1.000000. mean reward 233.248062.\n",
      "World Perf: Episode 2011.000000. Reward 200.000000. action: 1.000000. mean reward 233.718399.\n",
      "World Perf: Episode 2014.000000. Reward 200.000000. action: 1.000000. mean reward 234.040298.\n",
      "World Perf: Episode 2017.000000. Reward 194.000000. action: 0.000000. mean reward 234.669800.\n",
      "World Perf: Episode 2020.000000. Reward 200.000000. action: 1.000000. mean reward 233.941818.\n",
      "World Perf: Episode 2023.000000. Reward 200.000000. action: 0.000000. mean reward 233.829117.\n",
      "World Perf: Episode 2026.000000. Reward 200.000000. action: 0.000000. mean reward 234.143723.\n",
      "World Perf: Episode 2029.000000. Reward 200.000000. action: 0.000000. mean reward 234.616959.\n",
      "World Perf: Episode 2032.000000. Reward 200.000000. action: 1.000000. mean reward 234.952698.\n",
      "World Perf: Episode 2035.000000. Reward 200.000000. action: 0.000000. mean reward 235.191910.\n",
      "World Perf: Episode 2038.000000. Reward 200.000000. action: 1.000000. mean reward 235.485901.\n",
      "World Perf: Episode 2041.000000. Reward 200.000000. action: 1.000000. mean reward 235.759628.\n",
      "World Perf: Episode 2044.000000. Reward 200.000000. action: 0.000000. mean reward 236.030807.\n",
      "World Perf: Episode 2047.000000. Reward 200.000000. action: 1.000000. mean reward 236.483170.\n",
      "World Perf: Episode 2050.000000. Reward 200.000000. action: 1.000000. mean reward 236.728622.\n",
      "World Perf: Episode 2053.000000. Reward 200.000000. action: 1.000000. mean reward 237.217392.\n",
      "World Perf: Episode 2056.000000. Reward 200.000000. action: 1.000000. mean reward 237.441162.\n",
      "World Perf: Episode 2059.000000. Reward 200.000000. action: 0.000000. mean reward 237.999985.\n",
      "World Perf: Episode 2062.000000. Reward 200.000000. action: 0.000000. mean reward 238.239624.\n",
      "World Perf: Episode 2065.000000. Reward 200.000000. action: 0.000000. mean reward 238.485489.\n",
      "World Perf: Episode 2068.000000. Reward 200.000000. action: 1.000000. mean reward 238.750671.\n",
      "World Perf: Episode 2071.000000. Reward 200.000000. action: 1.000000. mean reward 238.946701.\n",
      "World Perf: Episode 2074.000000. Reward 200.000000. action: 1.000000. mean reward 239.165817.\n",
      "World Perf: Episode 2077.000000. Reward 200.000000. action: 0.000000. mean reward 239.324585.\n",
      "World Perf: Episode 2080.000000. Reward 200.000000. action: 0.000000. mean reward 239.514481.\n",
      "World Perf: Episode 2083.000000. Reward 200.000000. action: 0.000000. mean reward 237.953384.\n",
      "World Perf: Episode 2086.000000. Reward 200.000000. action: 1.000000. mean reward 237.414017.\n",
      "World Perf: Episode 2089.000000. Reward 200.000000. action: 1.000000. mean reward 237.195267.\n",
      "World Perf: Episode 2092.000000. Reward 200.000000. action: 0.000000. mean reward 237.445206.\n",
      "World Perf: Episode 2095.000000. Reward 200.000000. action: 0.000000. mean reward 237.691910.\n",
      "World Perf: Episode 2098.000000. Reward 200.000000. action: 0.000000. mean reward 237.905380.\n",
      "World Perf: Episode 2101.000000. Reward 200.000000. action: 1.000000. mean reward 238.164566.\n",
      "World Perf: Episode 2104.000000. Reward 200.000000. action: 0.000000. mean reward 238.384720.\n",
      "World Perf: Episode 2107.000000. Reward 200.000000. action: 1.000000. mean reward 238.626633.\n",
      "World Perf: Episode 2110.000000. Reward 200.000000. action: 1.000000. mean reward 238.858536.\n",
      "World Perf: Episode 2113.000000. Reward 200.000000. action: 0.000000. mean reward 239.068771.\n",
      "World Perf: Episode 2116.000000. Reward 200.000000. action: 1.000000. mean reward 239.315842.\n",
      "World Perf: Episode 2119.000000. Reward 200.000000. action: 1.000000. mean reward 239.507156.\n",
      "World Perf: Episode 2122.000000. Reward 200.000000. action: 0.000000. mean reward 239.179337.\n",
      "World Perf: Episode 2125.000000. Reward 200.000000. action: 1.000000. mean reward 239.000122.\n",
      "World Perf: Episode 2128.000000. Reward 200.000000. action: 1.000000. mean reward 239.245300.\n",
      "World Perf: Episode 2131.000000. Reward 200.000000. action: 0.000000. mean reward 238.490051.\n",
      "World Perf: Episode 2134.000000. Reward 200.000000. action: 0.000000. mean reward 237.996155.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "World Perf: Episode 2137.000000. Reward 200.000000. action: 0.000000. mean reward 238.232117.\n",
      "World Perf: Episode 2140.000000. Reward 200.000000. action: 0.000000. mean reward 238.481018.\n",
      "World Perf: Episode 2143.000000. Reward 200.000000. action: 0.000000. mean reward 238.698013.\n",
      "World Perf: Episode 2146.000000. Reward 200.000000. action: 1.000000. mean reward 238.916000.\n",
      "World Perf: Episode 2149.000000. Reward 200.000000. action: 1.000000. mean reward 239.123657.\n",
      "World Perf: Episode 2152.000000. Reward 200.000000. action: 1.000000. mean reward 239.338882.\n",
      "World Perf: Episode 2155.000000. Reward 200.000000. action: 0.000000. mean reward 238.894348.\n",
      "World Perf: Episode 2158.000000. Reward 200.000000. action: 0.000000. mean reward 239.153137.\n",
      "World Perf: Episode 2161.000000. Reward 200.000000. action: 1.000000. mean reward 239.007568.\n",
      "World Perf: Episode 2164.000000. Reward 200.000000. action: 1.000000. mean reward 239.230957.\n",
      "World Perf: Episode 2167.000000. Reward 200.000000. action: 0.000000. mean reward 239.267715.\n",
      "World Perf: Episode 2170.000000. Reward 200.000000. action: 0.000000. mean reward 239.483170.\n",
      "World Perf: Episode 2173.000000. Reward 200.000000. action: 0.000000. mean reward 239.701050.\n",
      "World Perf: Episode 2176.000000. Reward 200.000000. action: 1.000000. mean reward 239.890976.\n",
      "World Perf: Episode 2179.000000. Reward 200.000000. action: 1.000000. mean reward 239.596191.\n",
      "World Perf: Episode 2182.000000. Reward 200.000000. action: 1.000000. mean reward 239.810623.\n",
      "World Perf: Episode 2185.000000. Reward 200.000000. action: 1.000000. mean reward 239.998413.\n",
      "World Perf: Episode 2188.000000. Reward 200.000000. action: 0.000000. mean reward 239.747864.\n",
      "World Perf: Episode 2191.000000. Reward 200.000000. action: 1.000000. mean reward 239.948227.\n",
      "World Perf: Episode 2194.000000. Reward 200.000000. action: 1.000000. mean reward 240.145035.\n",
      "World Perf: Episode 2197.000000. Reward 200.000000. action: 1.000000. mean reward 240.120407.\n",
      "World Perf: Episode 2200.000000. Reward 200.000000. action: 1.000000. mean reward 239.656067.\n",
      "World Perf: Episode 2203.000000. Reward 200.000000. action: 0.000000. mean reward 239.878067.\n",
      "World Perf: Episode 2206.000000. Reward 200.000000. action: 1.000000. mean reward 240.141739.\n",
      "World Perf: Episode 2209.000000. Reward 200.000000. action: 0.000000. mean reward 240.377304.\n",
      "World Perf: Episode 2212.000000. Reward 200.000000. action: 1.000000. mean reward 240.664627.\n",
      "World Perf: Episode 2215.000000. Reward 200.000000. action: 1.000000. mean reward 240.911453.\n",
      "World Perf: Episode 2218.000000. Reward 200.000000. action: 1.000000. mean reward 241.218262.\n",
      "World Perf: Episode 2221.000000. Reward 200.000000. action: 0.000000. mean reward 241.402908.\n",
      "World Perf: Episode 2224.000000. Reward 200.000000. action: 0.000000. mean reward 241.648499.\n",
      "World Perf: Episode 2227.000000. Reward 200.000000. action: 0.000000. mean reward 241.828934.\n",
      "World Perf: Episode 2230.000000. Reward 200.000000. action: 1.000000. mean reward 241.451736.\n",
      "World Perf: Episode 2233.000000. Reward 200.000000. action: 1.000000. mean reward 241.616806.\n",
      "World Perf: Episode 2236.000000. Reward 200.000000. action: 1.000000. mean reward 241.776962.\n",
      "World Perf: Episode 2239.000000. Reward 200.000000. action: 0.000000. mean reward 241.926163.\n",
      "World Perf: Episode 2242.000000. Reward 200.000000. action: 0.000000. mean reward 242.080887.\n",
      "World Perf: Episode 2245.000000. Reward 200.000000. action: 0.000000. mean reward 242.269531.\n",
      "World Perf: Episode 2248.000000. Reward 200.000000. action: 1.000000. mean reward 242.419540.\n",
      "World Perf: Episode 2251.000000. Reward 200.000000. action: 0.000000. mean reward 242.564636.\n",
      "World Perf: Episode 2254.000000. Reward 200.000000. action: 0.000000. mean reward 242.700806.\n",
      "World Perf: Episode 2257.000000. Reward 200.000000. action: 1.000000. mean reward 242.888550.\n",
      "World Perf: Episode 2260.000000. Reward 200.000000. action: 1.000000. mean reward 243.022522.\n",
      "World Perf: Episode 2263.000000. Reward 200.000000. action: 1.000000. mean reward 242.789551.\n",
      "World Perf: Episode 2266.000000. Reward 200.000000. action: 1.000000. mean reward 242.915756.\n",
      "World Perf: Episode 2269.000000. Reward 200.000000. action: 1.000000. mean reward 243.048401.\n",
      "World Perf: Episode 2272.000000. Reward 176.333333. action: 1.000000. mean reward 242.966934.\n",
      "World Perf: Episode 2275.000000. Reward 200.000000. action: 0.000000. mean reward 242.982620.\n",
      "World Perf: Episode 2278.000000. Reward 200.000000. action: 1.000000. mean reward 243.233032.\n",
      "World Perf: Episode 2281.000000. Reward 200.000000. action: 1.000000. mean reward 243.140213.\n",
      "World Perf: Episode 2284.000000. Reward 200.000000. action: 0.000000. mean reward 241.283340.\n",
      "World Perf: Episode 2287.000000. Reward 200.000000. action: 1.000000. mean reward 241.692856.\n",
      "World Perf: Episode 2290.000000. Reward 200.000000. action: 0.000000. mean reward 241.903976.\n",
      "World Perf: Episode 2293.000000. Reward 200.000000. action: 0.000000. mean reward 242.095139.\n",
      "World Perf: Episode 2296.000000. Reward 200.000000. action: 1.000000. mean reward 242.280701.\n",
      "World Perf: Episode 2299.000000. Reward 200.000000. action: 1.000000. mean reward 242.451309.\n",
      "World Perf: Episode 2302.000000. Reward 200.000000. action: 1.000000. mean reward 242.606857.\n",
      "World Perf: Episode 2305.000000. Reward 200.000000. action: 0.000000. mean reward 242.765976.\n",
      "World Perf: Episode 2308.000000. Reward 200.000000. action: 0.000000. mean reward 242.235825.\n",
      "World Perf: Episode 2311.000000. Reward 200.000000. action: 0.000000. mean reward 241.802872.\n",
      "World Perf: Episode 2314.000000. Reward 200.000000. action: 1.000000. mean reward 241.945312.\n",
      "World Perf: Episode 2317.000000. Reward 200.000000. action: 0.000000. mean reward 241.540649.\n",
      "World Perf: Episode 2320.000000. Reward 200.000000. action: 0.000000. mean reward 241.976761.\n",
      "World Perf: Episode 2323.000000. Reward 200.000000. action: 1.000000. mean reward 239.725906.\n",
      "World Perf: Episode 2326.000000. Reward 200.000000. action: 1.000000. mean reward 238.901443.\n",
      "World Perf: Episode 2329.000000. Reward 200.000000. action: 1.000000. mean reward 239.676147.\n",
      "World Perf: Episode 2332.000000. Reward 200.000000. action: 1.000000. mean reward 237.359009.\n",
      "World Perf: Episode 2335.000000. Reward 200.000000. action: 0.000000. mean reward 235.274109.\n",
      "World Perf: Episode 2338.000000. Reward 200.000000. action: 0.000000. mean reward 235.616440.\n",
      "World Perf: Episode 2341.000000. Reward 200.000000. action: 1.000000. mean reward 235.012100.\n",
      "World Perf: Episode 2344.000000. Reward 200.000000. action: 1.000000. mean reward 235.360168.\n",
      "World Perf: Episode 2347.000000. Reward 200.000000. action: 0.000000. mean reward 235.131973.\n",
      "World Perf: Episode 2350.000000. Reward 200.000000. action: 1.000000. mean reward 235.395157.\n",
      "World Perf: Episode 2353.000000. Reward 200.000000. action: 0.000000. mean reward 235.669815.\n",
      "World Perf: Episode 2356.000000. Reward 200.000000. action: 1.000000. mean reward 235.862976.\n",
      "World Perf: Episode 2359.000000. Reward 200.000000. action: 0.000000. mean reward 233.592117.\n",
      "World Perf: Episode 2362.000000. Reward 200.000000. action: 0.000000. mean reward 232.471146.\n",
      "World Perf: Episode 2365.000000. Reward 200.000000. action: 0.000000. mean reward 230.161133.\n",
      "World Perf: Episode 2368.000000. Reward 200.000000. action: 0.000000. mean reward 230.714493.\n",
      "World Perf: Episode 2371.000000. Reward 200.000000. action: 0.000000. mean reward 231.103775.\n",
      "World Perf: Episode 2374.000000. Reward 200.000000. action: 1.000000. mean reward 231.435867.\n",
      "World Perf: Episode 2377.000000. Reward 200.000000. action: 1.000000. mean reward 230.858749.\n",
      "World Perf: Episode 2380.000000. Reward 200.000000. action: 1.000000. mean reward 231.229568.\n",
      "World Perf: Episode 2383.000000. Reward 200.000000. action: 0.000000. mean reward 231.624023.\n",
      "World Perf: Episode 2386.000000. Reward 200.000000. action: 0.000000. mean reward 229.777710.\n",
      "World Perf: Episode 2389.000000. Reward 200.000000. action: 0.000000. mean reward 230.215988.\n",
      "World Perf: Episode 2392.000000. Reward 200.000000. action: 0.000000. mean reward 229.042603.\n",
      "World Perf: Episode 2395.000000. Reward 200.000000. action: 1.000000. mean reward 229.473862.\n",
      "World Perf: Episode 2398.000000. Reward 200.000000. action: 0.000000. mean reward 229.854904.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "World Perf: Episode 2401.000000. Reward 200.000000. action: 1.000000. mean reward 230.265320.\n",
      "World Perf: Episode 2404.000000. Reward 200.000000. action: 1.000000. mean reward 230.661179.\n",
      "World Perf: Episode 2407.000000. Reward 200.000000. action: 1.000000. mean reward 231.025070.\n",
      "World Perf: Episode 2410.000000. Reward 200.000000. action: 1.000000. mean reward 231.426498.\n",
      "World Perf: Episode 2413.000000. Reward 200.000000. action: 1.000000. mean reward 231.789566.\n",
      "World Perf: Episode 2416.000000. Reward 200.000000. action: 1.000000. mean reward 232.138535.\n",
      "World Perf: Episode 2419.000000. Reward 200.000000. action: 1.000000. mean reward 232.581161.\n",
      "World Perf: Episode 2422.000000. Reward 155.333333. action: 0.000000. mean reward 232.489944.\n",
      "World Perf: Episode 2425.000000. Reward 200.000000. action: 0.000000. mean reward 232.864609.\n",
      "World Perf: Episode 2428.000000. Reward 200.000000. action: 0.000000. mean reward 233.202530.\n",
      "World Perf: Episode 2431.000000. Reward 200.000000. action: 0.000000. mean reward 233.518250.\n",
      "World Perf: Episode 2434.000000. Reward 200.000000. action: 0.000000. mean reward 232.278061.\n",
      "World Perf: Episode 2437.000000. Reward 200.000000. action: 1.000000. mean reward 231.215347.\n",
      "World Perf: Episode 2440.000000. Reward 200.000000. action: 1.000000. mean reward 230.107590.\n",
      "World Perf: Episode 2443.000000. Reward 200.000000. action: 1.000000. mean reward 227.800781.\n",
      "World Perf: Episode 2446.000000. Reward 200.000000. action: 1.000000. mean reward 228.209335.\n",
      "World Perf: Episode 2449.000000. Reward 200.000000. action: 1.000000. mean reward 226.381516.\n",
      "World Perf: Episode 2452.000000. Reward 200.000000. action: 0.000000. mean reward 226.008606.\n",
      "World Perf: Episode 2455.000000. Reward 200.000000. action: 0.000000. mean reward 226.507141.\n",
      "World Perf: Episode 2458.000000. Reward 200.000000. action: 0.000000. mean reward 226.240067.\n",
      "World Perf: Episode 2461.000000. Reward 200.000000. action: 1.000000. mean reward 226.712341.\n",
      "World Perf: Episode 2464.000000. Reward 200.000000. action: 0.000000. mean reward 227.182556.\n",
      "World Perf: Episode 2467.000000. Reward 200.000000. action: 0.000000. mean reward 227.657104.\n",
      "World Perf: Episode 2470.000000. Reward 200.000000. action: 1.000000. mean reward 226.904297.\n",
      "World Perf: Episode 2473.000000. Reward 200.000000. action: 0.000000. mean reward 227.418259.\n",
      "World Perf: Episode 2476.000000. Reward 200.000000. action: 0.000000. mean reward 226.619247.\n",
      "World Perf: Episode 2479.000000. Reward 200.000000. action: 1.000000. mean reward 227.136093.\n",
      "World Perf: Episode 2482.000000. Reward 200.000000. action: 0.000000. mean reward 227.646469.\n",
      "World Perf: Episode 2485.000000. Reward 200.000000. action: 1.000000. mean reward 225.659302.\n",
      "World Perf: Episode 2488.000000. Reward 200.000000. action: 0.000000. mean reward 226.232666.\n",
      "World Perf: Episode 2491.000000. Reward 200.000000. action: 0.000000. mean reward 226.671219.\n",
      "World Perf: Episode 2494.000000. Reward 200.000000. action: 1.000000. mean reward 227.238144.\n",
      "World Perf: Episode 2497.000000. Reward 200.000000. action: 0.000000. mean reward 227.744507.\n",
      "World Perf: Episode 2500.000000. Reward 200.000000. action: 1.000000. mean reward 228.247131.\n",
      "World Perf: Episode 2503.000000. Reward 200.000000. action: 0.000000. mean reward 228.676743.\n",
      "World Perf: Episode 2506.000000. Reward 200.000000. action: 0.000000. mean reward 229.128479.\n",
      "World Perf: Episode 2509.000000. Reward 200.000000. action: 1.000000. mean reward 229.593750.\n",
      "World Perf: Episode 2512.000000. Reward 200.000000. action: 0.000000. mean reward 230.040573.\n",
      "World Perf: Episode 2515.000000. Reward 200.000000. action: 1.000000. mean reward 230.463318.\n",
      "World Perf: Episode 2518.000000. Reward 200.000000. action: 1.000000. mean reward 230.876846.\n",
      "World Perf: Episode 2521.000000. Reward 200.000000. action: 1.000000. mean reward 230.025345.\n",
      "World Perf: Episode 2524.000000. Reward 200.000000. action: 1.000000. mean reward 230.444809.\n",
      "World Perf: Episode 2527.000000. Reward 200.000000. action: 1.000000. mean reward 229.011642.\n",
      "World Perf: Episode 2530.000000. Reward 200.000000. action: 0.000000. mean reward 229.401352.\n",
      "World Perf: Episode 2533.000000. Reward 200.000000. action: 0.000000. mean reward 229.780884.\n",
      "World Perf: Episode 2536.000000. Reward 200.000000. action: 1.000000. mean reward 228.890335.\n",
      "World Perf: Episode 2539.000000. Reward 200.000000. action: 0.000000. mean reward 229.292374.\n",
      "World Perf: Episode 2542.000000. Reward 200.000000. action: 1.000000. mean reward 229.705002.\n",
      "World Perf: Episode 2545.000000. Reward 200.000000. action: 0.000000. mean reward 230.094116.\n",
      "World Perf: Episode 2548.000000. Reward 200.000000. action: 0.000000. mean reward 230.480423.\n",
      "World Perf: Episode 2551.000000. Reward 200.000000. action: 0.000000. mean reward 230.874344.\n",
      "2551\n"
     ]
    }
   ],
   "source": [
    "xs,drs,ys,ds = [],[],[],[]\n",
    "running_reward = None\n",
    "reward_sum = 0\n",
    "episode_number = 1\n",
    "real_episodes = 1\n",
    "init = tf.global_variables_initializer()\n",
    "batch_size = real_bs\n",
    "\n",
    "drawFromModel = False # When set to True, will use model for observations\n",
    "trainTheModel = True # Whether to train the model\n",
    "trainThePolicy = False # Whether to train the policy\n",
    "switch_point = 1\n",
    "\n",
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    rendering = False\n",
    "    sess.run(init)\n",
    "    observation = env.reset()\n",
    "    x = observation\n",
    "    gradBuffer = sess.run(tvars)\n",
    "    gradBuffer = resetGradBuffer(gradBuffer)\n",
    "    \n",
    "    while episode_number <= 5000:\n",
    "        # Start displaying environment once performance is acceptably high.\n",
    "        if (reward_sum/batch_size > 150 and drawFromModel == False) or rendering == True : \n",
    "            #env.render()\n",
    "            #rendering = True\n",
    "            pass # seriously rendering this is so slow\n",
    "            \n",
    "        x = np.reshape(observation,[1,4])\n",
    "\n",
    "        tfprob = sess.run(probability,feed_dict={observations: x})\n",
    "        action = 1 if np.random.uniform() < tfprob else 0\n",
    "\n",
    "        # record various intermediates (needed later for backprop)\n",
    "        xs.append(x) \n",
    "        y = 1 if action == 0 else 0 \n",
    "        ys.append(y)\n",
    "        \n",
    "        # step the  model or real environment and get new measurements\n",
    "        if drawFromModel == False:\n",
    "            observation, reward, done, info = env.step(action)\n",
    "        else:\n",
    "            observation, reward, done = stepModel(sess,xs,action)\n",
    "                \n",
    "        reward_sum += reward\n",
    "        \n",
    "        ds.append(done*1)\n",
    "        drs.append(reward) # record reward (has to be done after we call step() to get reward for previous action)\n",
    "\n",
    "        if done: \n",
    "            \n",
    "            if drawFromModel == False: \n",
    "                real_episodes += 1\n",
    "            episode_number += 1\n",
    "\n",
    "            # stack together all inputs, hidden states, action gradients, and rewards for this episode\n",
    "            epx = np.vstack(xs)\n",
    "            epy = np.vstack(ys)\n",
    "            epr = np.vstack(drs)\n",
    "            epd = np.vstack(ds)\n",
    "            xs,drs,ys,ds = [],[],[],[] # reset array memory\n",
    "            \n",
    "            if trainTheModel == True:\n",
    "                ################################################################################\n",
    "                # TODO: Run the model network and compute predicted_state                      #\n",
    "                # Output: 'pState'                                                             #\n",
    "                ################################################################################\n",
    "                actions = np.array([np.abs(y-1) for y in epy][:-1])\n",
    "                \n",
    "                # Get all the prev variables\n",
    "                prev_state = epx[: -1, :]\n",
    "                prev_state = np.hstack([prev_state,actions])\n",
    "                \n",
    "                # Get all the variables for next state\n",
    "                next_state = epx[1: , :]\n",
    "                rewards = np.array(epr[1: , :])\n",
    "                dones = np.array(epd[1: , :])\n",
    "\n",
    "                pState, _ = sess.run([predicted_state,updateModel],feed_dict={previous_state: prev_state, \n",
    "                                                                                              true_observation: next_state,\n",
    "                                                                                              true_done:dones,\n",
    "                                                                                              true_reward:rewards})\n",
    "                ################################################################################\n",
    "                #                                 END OF YOUR CODE                             #\n",
    "                ################################################################################\n",
    "                \n",
    "\n",
    "            if trainThePolicy == True:\n",
    "                ################################################################################\n",
    "                # TODO: Run the policy network and compute newGrads                            #\n",
    "                # Output: 'tGrad'                                                              #\n",
    "                ################################################################################\n",
    "                # compute the discounted reward backwards through time\n",
    "                discounted_epr = discount_rewards(epr)\n",
    "                # size the rewards to be unit normal (helps control the gradient estimator variance)\n",
    "                discounted_epr -= np.mean(discounted_epr)\n",
    "                discounted_epr //= np.std(discounted_epr)\n",
    "                tGrad = sess.run(newGrads, feed_dict={input_y: epy, observations: epx, advantages: discounted_epr})\n",
    "                ################################################################################\n",
    "                #                                 END OF YOUR CODE                             #\n",
    "                ################################################################################\n",
    "                \n",
    "                # If gradients becom too large, end training process\n",
    "                if np.sum(tGrad[0] == tGrad[0]) == 0:\n",
    "                    break\n",
    "                for ix,grad in enumerate(tGrad):\n",
    "                    gradBuffer[ix] += grad\n",
    "                \n",
    "            if switch_point + batch_size == episode_number: \n",
    "                switch_point = episode_number\n",
    "                if trainThePolicy == True:\n",
    "                    \n",
    "                    ################################################################################\n",
    "                    # TODO:                                                                        #\n",
    "                    # (1) Run the policy network and update gradients                              #\n",
    "                    # (2) Reset gradBuffer to 0                                                    #\n",
    "                    ################################################################################\n",
    "                    _ = sess.run(updateGrads, feed_dict={W1Grad: gradBuffer[0], \n",
    "                                                         W2Grad: gradBuffer[1]})\n",
    "                    for ix,grad in enumerate(gradBuffer):\n",
    "                        gradBuffer[ix] = grad * 0\n",
    "                    ################################################################################\n",
    "                    #                                 END OF YOUR CODE                             #\n",
    "                    ################################################################################\n",
    "\n",
    "                running_reward = reward_sum if running_reward is None else running_reward * 0.99 + reward_sum * 0.01\n",
    "                if drawFromModel == False:\n",
    "                    print('World Perf: Episode %f. Reward %f. action: %f. mean reward %f.' % (real_episodes,reward_sum/real_bs,action, running_reward/real_bs))\n",
    "                    if reward_sum/batch_size > 200:\n",
    "                        break\n",
    "                reward_sum = 0\n",
    "\n",
    "                # Once the model has been trained on 100 episodes\n",
    "                if episode_number > 100:\n",
    "\n",
    "                    ################################################################################\n",
    "                    # TODO: Alternating between training the policy from the model and training    #\n",
    "                    # the model from the real environment.                                         #\n",
    "                    ################################################################################\n",
    "                    trainThePolicy = not trainThePolicy # Whether to train the policy\n",
    "                    trainTheModel = not trainTheModel # Whether to train the model\n",
    "                    drawFromModel = not drawFromModel # When set to True, will use model for observations\n",
    "\n",
    "                    ################################################################################\n",
    "                    #                                 END OF YOUR CODE                             #\n",
    "                    ################################################################################\n",
    "            \n",
    "            if drawFromModel == True:\n",
    "                observation = np.random.uniform(-0.1,0.1,[4]) # Generate reasonable starting point\n",
    "                batch_size = model_bs\n",
    "            else:\n",
    "                observation = env.reset()\n",
    "                batch_size = real_bs\n",
    "                \n",
    "print(real_episodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking model representation\n",
    "Here we can examine how well the model is able to approximate the true environment after training. The green line indicates the real environment, and the blue indicates model predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/budiryan/Documents/projects/COMP4901J/assignment4/.env/lib/python3.5/site-packages/matplotlib/cbook/deprecation.py:106: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  warnings.warn(message, mplDeprecation, stacklevel=1)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'state_nextsAll' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-ec5973aa3641>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpState\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_nextsAll\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtight_layout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'state_nextsAll' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQIAAACACAYAAADgQGc3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUEqhhUAphRYCpRTw/1c74VP3YJecAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8904868a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 12))\n",
    "for i in range(6):\n",
    "    plt.subplot(6, 2, 2*i + 1)\n",
    "    plt.plot(pState[:,i])\n",
    "    plt.subplot(6,2,2*i+1)\n",
    "    plt.plot(state_nextsAll[:,i])\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
